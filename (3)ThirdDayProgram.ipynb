{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAYALAIMMANUELRAJU/PySpark1/blob/main/(3)ThirdDayProgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUO7okyBshqq"
      },
      "source": [
        "## Linux Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULvxSGiufh5a",
        "outputId": "5fecfe28-18a2-45f7-e7b6-46268780a917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My name is IMMANUEL\n"
          ]
        }
      ],
      "source": [
        "print(\"My name is IMMANUEL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtYKaQ6YfzLY",
        "outputId": "dd586395-7a8e-4233-9995-63b221320b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIDdvXXOpnyB",
        "outputId": "b5aefd51-c53e-433c-f559-a6faa66adf67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PRETTY_NAME=\"Ubuntu 22.04.4 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION_ID=\"22.04\"\n",
            "VERSION=\"22.04.4 LTS (Jammy Jellyfish)\"\n",
            "VERSION_CODENAME=jammy\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "UBUNTU_CODENAME=jammy\n"
          ]
        }
      ],
      "source": [
        "!cat /etc/os-release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhZ0eUnEpwyD",
        "outputId": "ebe0475b-f8e3-4908-9300-3d8df4b9053c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linux ad781dd04101 6.1.123+ #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ],
      "source": [
        "!uname -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUcoAJwLp_N9",
        "outputId": "f1fca487-68c6-4abe-c2e2-3e6b84cf33ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n"
          ]
        }
      ],
      "source": [
        "!whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn9sE_F1qDsL",
        "outputId": "79b0cf88-5d70-4acd-c071-44bafd8bff3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijZbN5F4ttVO"
      },
      "source": [
        "## PySpark Basics of DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCU_gQrltx08",
        "outputId": "b8598214-9b97-4a40-aa6a-467f2a86e8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNyJ0IHwt3fp",
        "outputId": "3f8ae306-b6ee-4be2-f502-dd7172c6da83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.27\n",
            "Branch HEAD\n",
            "Compiled by user heartsavior on 2024-02-15T11:24:58Z\n",
            "Revision fd86f85e181fc2dc0f50a096855acf83a6cc5d9c\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ],
      "source": [
        "!pyspark --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5spRMYV4t-LY"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPpNpXkNuaca"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht1wVILnu9ZT"
      },
      "outputs": [],
      "source": [
        "# Create DataFrame\n",
        "data = [(\"Hello\", \"World\")]\n",
        "columns = [\"Word1\", \"Word2\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m47WqPudvhuI",
        "outputId": "2f106c18-35be-4264-bb0e-3ad4464a7458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|Word1|Word2|\n",
            "+-----+-----+\n",
            "|Hello|World|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpPnpP-oxBDw"
      },
      "source": [
        "## Basic Transformation and Actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_7I-4G-wd-m",
        "outputId": "74093af9-82b8-492b-f202-acfb9dd62458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "columns =[\"Name\", \"Department\", \"Salary\"]\n",
        "data = [\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Jane\", \"Finance\", 4000),\n",
        "    (\"Mike\", \"Sales\", 3500),\n",
        "    (\"Alice\", \"Finance\", 3800),\n",
        "    (\"Bob\",\"IT\",4500)\n",
        "]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IdkwqLdwsRt",
        "outputId": "cf2eccb8-2f6d-462a-b7a8-5831ae2283e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| Jane|   Finance|  4000|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filter: Employees with salary > 3500\n",
        "df_filtered = df.filter(df.Salary > 3500)\n",
        "df_filtered.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEd5e6tqyJny",
        "outputId": "10b39a6b-8308-4d67-b703-eb24b6bf3849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GroupBy and Aggregate: Avarage salary by department\n",
        "df_grouped =df.groupBy(\"Department\").avg(\"Salary\")\n",
        "df_grouped.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufGut94vyyD9",
        "outputId": "fbf3cf70-51de-444b-b966-1a6245b6d99e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+------------------+\n",
            "| Name|Department|Salary|  Salary_10%_Bonus|\n",
            "+-----+----------+------+------------------+\n",
            "| John|     Sales|  3000|3300.0000000000005|\n",
            "| Jane|   Finance|  4000|            4400.0|\n",
            "| Mike|     Sales|  3500|3850.0000000000005|\n",
            "|Alice|   Finance|  3800|            4180.0|\n",
            "|  Bob|        IT|  4500|            4950.0|\n",
            "+-----+----------+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add a new column: Salary with bonus (10%)\n",
        "from pyspark.sql.functions import col\n",
        "exp =col(\"Salary\") * 1.1\n",
        "df_bonus = df.withColumn(\"Salary_10%_Bonus\", exp)\n",
        "df_bonus.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXwMeOp20iI4",
        "outputId": "4a3069ba-8a72-4333-abab-654fe667cd60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col,upper,lower, concat_ws,length,when\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slfFr1an2DSJ",
        "outputId": "c486716b-ea52-4da1-f677-17f6cde3859d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+----------+\n",
            "| Name|Department|Salary|Name_Upper|\n",
            "+-----+----------+------+----------+\n",
            "| John|     Sales|  3000|      JOHN|\n",
            "| Jane|   Finance|  4000|      JANE|\n",
            "| Mike|     Sales|  3500|      MIKE|\n",
            "|Alice|   Finance|  3800|     ALICE|\n",
            "|  Bob|        IT|  4500|       BOB|\n",
            "+-----+----------+------+----------+\n",
            "\n",
            "+-----+----------+------+----------+\n",
            "| Name|Department|Salary|Name_Lower|\n",
            "+-----+----------+------+----------+\n",
            "| John|     Sales|  3000|      john|\n",
            "| Jane|   Finance|  4000|      jane|\n",
            "| Mike|     Sales|  3500|      mike|\n",
            "|Alice|   Finance|  3800|     alice|\n",
            "|  Bob|        IT|  4500|       bob|\n",
            "+-----+----------+------+----------+\n",
            "\n",
            "+-----+----------+------+---------------+\n",
            "| Name|Department|Salary|Name_Department|\n",
            "+-----+----------+------+---------------+\n",
            "| John|     Sales|  3000|   John - Sales|\n",
            "| Jane|   Finance|  4000| Jane - Finance|\n",
            "| Mike|     Sales|  3500|   Mike - Sales|\n",
            "|Alice|   Finance|  3800|Alice - Finance|\n",
            "|  Bob|        IT|  4500|       Bob - IT|\n",
            "+-----+----------+------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Change Case Tranformation\n",
        "df_upper= df.withColumn(\"Name_Upper\", upper(col(\"Name\")))\n",
        "df_lower= df.withColumn(\"Name_Lower\", lower(col(\"Name\")))\n",
        "df_concat = df.withColumn(\"Name_Department\", concat_ws(\" - \", col(\"Name\"), col(\"Department\")))\n",
        "df_upper.show()\n",
        "df_lower.show()\n",
        "df_concat.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y13I2x-2qpm",
        "outputId": "b447ed77-6bca-42d5-b63d-56d8935ad9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+-------------+\n",
            "| Name|Department|Salary|    Full_Name|\n",
            "+-----+----------+------+-------------+\n",
            "| John|     Sales|  3000|   John Sales|\n",
            "| Jane|   Finance|  4000| Jane Finance|\n",
            "| Mike|     Sales|  3500|   Mike Sales|\n",
            "|Alice|   Finance|  3800|Alice Finance|\n",
            "|  Bob|        IT|  4500|       Bob IT|\n",
            "+-----+----------+------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Concatenate the Columns\n",
        "df_concat =df.withColumn(\"Full_Name\", concat_ws(\" \", col(\"Name\"), col(\"Department\")))\n",
        "df_concat.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCd4Dp143OFf",
        "outputId": "897eb3b5-0efd-44ad-bce8-15357cf86c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+-----------+\n",
            "| Name|Department|Salary|Name_Length|\n",
            "+-----+----------+------+-----------+\n",
            "| John|     Sales|  3000|          4|\n",
            "| Jane|   Finance|  4000|          4|\n",
            "| Mike|     Sales|  3500|          4|\n",
            "|Alice|   Finance|  3800|          5|\n",
            "|  Bob|        IT|  4500|          3|\n",
            "+-----+----------+------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# String length of Names in New DF\n",
        "df_length = df.withColumn(\"Name_Length\", length(col(\"Name\")))\n",
        "df_length.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-6kqMvi3gBa",
        "outputId": "cdfcc9b0-ac92-4235-a547-c64d6a7c06e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+---------------+\n",
            "| Name|Department|Salary|Salary_Category|\n",
            "+-----+----------+------+---------------+\n",
            "| John|     Sales|  3000|            Low|\n",
            "| Jane|   Finance|  4000|           High|\n",
            "| Mike|     Sales|  3500|         Medium|\n",
            "|Alice|   Finance|  3800|         Medium|\n",
            "|  Bob|        IT|  4500|           High|\n",
            "+-----+----------+------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Conditional Column (Salary Category\n",
        "df_conditional =df.withColumn(\"Salary_Category\",\n",
        "                               when(col(\"Salary\") >= 4000, \"High\")\n",
        "                               .when(col(\"Salary\") >= 3500, \"Medium\")\n",
        "                               .otherwise(\"Low\"))\n",
        "df_conditional.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnBZa4qW4q1p",
        "outputId": "a5873623-7e93-463b-8fcd-b199811d51cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+-----------+\n",
            "| Name|Department|Base_Salary|\n",
            "+-----+----------+-----------+\n",
            "| John|     Sales|       3000|\n",
            "| Jane|   Finance|       4000|\n",
            "| Mike|     Sales|       3500|\n",
            "|Alice|   Finance|       3800|\n",
            "|  Bob|        IT|       4500|\n",
            "+-----+----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Rename Column (Salary --> Base_Salary)\n",
        "df_renamed = df.withColumnRenamed(\"Salary\", \"Base_Salary\")\n",
        "df_renamed.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCvuGCzBN8EW"
      },
      "source": [
        "## Advance Transformation and Action in PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXNO17aXORtM",
        "outputId": "92d3c9df-9bac-4f71-c8c4-c3c8c6ecb905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark =SparkSession.builder.appName(\"Basics\").getOrCreate()\n",
        "columns = [\"Name\",\"Department\",\"Salary\"]\n",
        "data = [\n",
        "    (\"John\", \"Sales\", 3000),\n",
        "    (\"Jane\", \"Finance\", 4000),\n",
        "    (\"Mike\", \"Sales\", 3500),\n",
        "    (\"Alice\", \"Finance\", 3800),\n",
        "    (\"Bob\", \"IT\", 4500)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgiIpcw9OUVF",
        "outputId": "a9ca5a4c-d6d1-40f1-f685-25ada7e0ccfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|Department|count|\n",
            "+----------+-----+\n",
            "|     Sales|    2|\n",
            "|   Finance|    2|\n",
            "|        IT|    1|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GroupBy Department and count employees\n",
        "df.groupBy(\"Department\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVIY6w4POuro",
        "outputId": "826231be-6d33-4d55-bc9f-9fa7329efc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3250.0|\n",
            "|   Finance|     3900.0|\n",
            "|        IT|     4500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GroupBy Department and calculate average salary\n",
        "df.groupBy(\"Department\").avg(\"Salary\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2JlKBkcPClp",
        "outputId": "3fb35eaf-0e34-4315-da8e-5fbef5e3250c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------------+----------+----------+\n",
            "|Department|Average_Salary|Max_Salary|Min_Salary|\n",
            "+----------+--------------+----------+----------+\n",
            "|     Sales|        3250.0|      3500|      3000|\n",
            "|   Finance|        3900.0|      4000|      3800|\n",
            "|        IT|        4500.0|      4500|      4500|\n",
            "+----------+--------------+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GroupBy Department and calculate multiple Aggregations\n",
        "from pyspark.sql import functions as functions\n",
        "df.groupBy(\"Department\").agg(\n",
        "    functions.avg(\"Salary\").alias(\"Average_Salary\"),\n",
        "    functions.max(\"Salary\").alias(\"Max_Salary\"),\n",
        "    functions.min(\"Salary\").alias(\"Min_Salary\")\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1n7HnjiQF3P",
        "outputId": "3c5a03d9-b15f-4315-d653-d11331c48b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------+------+\n",
            "| Name|Department|Salary|\n",
            "+-----+----------+------+\n",
            "| John|     Sales|  3000|\n",
            "| Jane|   Finance|  4000|\n",
            "| Mike|     Sales|  3500|\n",
            "|Alice|   Finance|  3800|\n",
            "|  Bob|        IT|  4500|\n",
            "+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create another DataFrame for department info\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\")\n",
        "]\n",
        "dept_columns = [\"Department\",\"Location\"]\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VknhO6kSCuk",
        "outputId": "dcc2bf95-31f4-4001-911c-c25bb95b24ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+------+----------+\n",
            "|Department| Name|Salary|  Location|\n",
            "+----------+-----+------+----------+\n",
            "|   Finance| Jane|  4000|Building B|\n",
            "|   Finance|Alice|  3800|Building B|\n",
            "|        IT|  Bob|  4500|Building C|\n",
            "|     Sales| John|  3000|Building A|\n",
            "|     Sales| Mike|  3500|Building A|\n",
            "+----------+-----+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dept_df =spark.createDataFrame(dept_data, dept_columns)\n",
        "# Join employee data with department info\n",
        "joined_df = df.join(dept_df, on=\"Department\", how=\"inner\")\n",
        "joined_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_oCL5ZQSQnk",
        "outputId": "d0931db6-7d6e-4298-fdb6-bcd03fb57ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dept_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9N5UbZBSj-O",
        "outputId": "52f96b76-2886-4087-d434-f2a60188b6b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+------+----------+\n",
            "|Department| Name|Salary|  Location|\n",
            "+----------+-----+------+----------+\n",
            "|   Finance| Jane|  4000|Building B|\n",
            "|   Finance|Alice|  3800|Building B|\n",
            "|        IT|  Bob|  4500|Building C|\n",
            "|     Sales| John|  3000|Building A|\n",
            "|     Sales| Mike|  3500|Building A|\n",
            "+----------+-----+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Perform an outer join\n",
        "outer_joined_df = df.join(dept_df, on=\"Department\", how=\"outer\")\n",
        "outer_joined_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvf-0v96Uu53",
        "outputId": "b33c9670-a988-44e4-f3ad-22ad7fe8e6f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1| John|     Sales|  3000|\n",
            "|    2| Jane|   Finance|  4000|\n",
            "|    3| Mike|     Sales|  3500|\n",
            "|    4|Alice|        HR|  3800|\n",
            "|    5|  Bob|        IT|  4500|\n",
            "|    6|  Sam|   Support|  3200|\n",
            "+-----+-----+----------+------+\n",
            "\n",
            "+----------+----------+\n",
            "|Department|  Location|\n",
            "+----------+----------+\n",
            "|     Sales|Building A|\n",
            "|   Finance|Building B|\n",
            "|        IT|Building C|\n",
            "|     Admin|Building D|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Employee DataFrame\n",
        "emp_data = [\n",
        "    (1, \"John\", \"Sales\", 3000),\n",
        "    (2, \"Jane\", \"Finance\", 4000),\n",
        "    (3, \"Mike\", \"Sales\", 3500),\n",
        "    (4, \"Alice\", \"HR\", 3800),\n",
        "    (5, \"Bob\", \"IT\", 4500),\n",
        "    (6, \"Sam\", \"Support\", 3200)\n",
        "]\n",
        "emp_cols = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "emp_df = spark.createDataFrame(emp_data, emp_cols)\n",
        "\n",
        "# Department DataFrame\n",
        "dept_data = [\n",
        "    (\"Sales\", \"Building A\"),\n",
        "    (\"Finance\", \"Building B\"),\n",
        "    (\"IT\", \"Building C\"),\n",
        "    (\"Admin\", \"Building D\")\n",
        "]\n",
        "dept_cols = [\"Department\", \"Location\"]\n",
        "dept_df = spark.createDataFrame(dept_data, dept_cols)\n",
        "\n",
        "# Display both\n",
        "emp_df.show()\n",
        "dept_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVmdBI7bVJJO",
        "outputId": "e8959109-28ea-44ab-b03e-c53fbd873c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+----+------+----------+\n",
            "|Department|EmpID|Name|Salary|  Location|\n",
            "+----------+-----+----+------+----------+\n",
            "|   Finance|    2|Jane|  4000|Building B|\n",
            "|        IT|    5| Bob|  4500|Building C|\n",
            "|     Sales|    1|John|  3000|Building A|\n",
            "|     Sales|    3|Mike|  3500|Building A|\n",
            "+----------+-----+----+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Perform Inner Join\n",
        "emp_df.join(dept_df, on=\"Department\", how=\"inner\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JRQxr33VV_1",
        "outputId": "f867d177-946c-4b78-8d24-165852f67cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-----+------+----------+\n",
            "|Department|EmpID| Name|Salary|  Location|\n",
            "+----------+-----+-----+------+----------+\n",
            "|     Sales|    1| John|  3000|Building A|\n",
            "|     Sales|    3| Mike|  3500|Building A|\n",
            "|   Finance|    2| Jane|  4000|Building B|\n",
            "|        HR|    4|Alice|  3800|      NULL|\n",
            "|        IT|    5|  Bob|  4500|Building C|\n",
            "|   Support|    6|  Sam|  3200|      NULL|\n",
            "+----------+-----+-----+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Perfom Left Join (All Employees, Dept Info if Exists)\n",
        "emp_df.join(dept_df, on=\"Department\", how=\"left\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJeeQD3zVmv9",
        "outputId": "719a98d8-e037-4d8c-f49d-292d52f4d0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+----+------+----------+\n",
            "|Department|EmpID|Name|Salary|  Location|\n",
            "+----------+-----+----+------+----------+\n",
            "|     Sales|    3|Mike|  3500|Building A|\n",
            "|     Sales|    1|John|  3000|Building A|\n",
            "|   Finance|    2|Jane|  4000|Building B|\n",
            "|     Admin| NULL|NULL|  NULL|Building D|\n",
            "|        IT|    5| Bob|  4500|Building C|\n",
            "+----------+-----+----+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Perfom Right Join (All Employees, Dept Info if Exists)\n",
        "emp_df.join(dept_df, on=\"Department\", how=\"right\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6pMJAUHVx2l",
        "outputId": "1dfa5492-6c7d-494a-bcb1-56c02112701c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-----+------+----------+\n",
            "|Department|EmpID| Name|Salary|  Location|\n",
            "+----------+-----+-----+------+----------+\n",
            "|     Admin| NULL| NULL|  NULL|Building D|\n",
            "|   Finance|    2| Jane|  4000|Building B|\n",
            "|        HR|    4|Alice|  3800|      NULL|\n",
            "|        IT|    5|  Bob|  4500|Building C|\n",
            "|     Sales|    1| John|  3000|Building A|\n",
            "|     Sales|    3| Mike|  3500|Building A|\n",
            "|   Support|    6|  Sam|  3200|      NULL|\n",
            "+----------+-----+-----+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Perfom Full Join (All Employees, Dept Info if Exists)\n",
        "emp_df.join(dept_df, on=\"Department\", how=\"full\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCPIk367Ydfh"
      },
      "source": [
        "## Case Study Activity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDUaLhbRYhB9"
      },
      "outputs": [],
      "source": [
        "#  1. Setup: Load DataFrames\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum, avg, count, month, year, when, desc, row_number, min, max\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SalesAnalysis\").getOrCreate()\n",
        "\n",
        "# Load CSV files\n",
        "sales_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"sales_data.csv\")\n",
        "product_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"product_data.csv\")\n",
        "customer_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"customer_data.csv\")\n",
        "\n",
        "# Create revenue column\n",
        "sales_df = sales_df.withColumn(\"revenue\", col(\"quantity\") * col(\"price\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEbXJTlxYlIg",
        "outputId": "3eeef195-4902-490e-f083-5480d1a765af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------------+\n",
            "|product_id|total_revenue|\n",
            "+----------+-------------+\n",
            "|       148|         58.0|\n",
            "|       137|        115.0|\n",
            "|       133|        115.5|\n",
            "|       108|        235.0|\n",
            "|       101|        280.5|\n",
            "|       115|        484.0|\n",
            "|       126|        240.0|\n",
            "|       103|        240.0|\n",
            "|       128|         90.0|\n",
            "|       122|        100.0|\n",
            "|       111|        292.5|\n",
            "|       140|         80.0|\n",
            "|       132|        132.0|\n",
            "|       146|        180.0|\n",
            "|       142|        190.0|\n",
            "|       139|         55.5|\n",
            "|       120|        211.5|\n",
            "|       117|        114.0|\n",
            "|       112|        231.0|\n",
            "|       127|         70.0|\n",
            "+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. Aggregations\n",
        "# 2.1 Total Revenue Per Product\n",
        "total_revenue_product = sales_df.groupBy(\"product_id\").agg(sum(\"revenue\").alias(\"total_revenue\"))\n",
        "total_revenue_product.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4kiBXQfYxHw",
        "outputId": "b3e34d44-d6ef-42c3-bee6-e3ced569f329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|total_quantity|\n",
            "+-----------+--------------+\n",
            "|        540|             3|\n",
            "|        516|             4|\n",
            "|        513|             8|\n",
            "|        530|             2|\n",
            "|        501|             3|\n",
            "|        548|             9|\n",
            "|        539|             6|\n",
            "|        519|             6|\n",
            "|        556|             8|\n",
            "|        512|             9|\n",
            "|        570|             3|\n",
            "|        559|             6|\n",
            "|        545|             3|\n",
            "|        507|             3|\n",
            "|        544|             7|\n",
            "|        542|             8|\n",
            "|        553|             7|\n",
            "|        560|             5|\n",
            "|        504|             5|\n",
            "|        554|             5|\n",
            "+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2.2 Total Quantity Sold Per Customer\n",
        "quantity_per_customer = sales_df.groupBy(\"customer_id\").agg(sum(\"quantity\").alias(\"total_quantity\"))\n",
        "quantity_per_customer.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzl6inxaY2pk",
        "outputId": "572d0574-5840-4851-c13c-d778af2b30f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+\n",
            "|customer_id|avg_revenue|\n",
            "+-----------+-----------+\n",
            "|        540|       55.5|\n",
            "|        516|      128.0|\n",
            "|        513|      180.0|\n",
            "|        530|       76.0|\n",
            "|        501|       76.5|\n",
            "|        548|      198.0|\n",
            "|        539|      210.0|\n",
            "|        519|      111.0|\n",
            "|        556|      400.0|\n",
            "|        512|       90.0|\n",
            "|        570|      120.0|\n",
            "|        559|      108.0|\n",
            "|        545|       91.5|\n",
            "|        507|      120.0|\n",
            "|        544|       84.0|\n",
            "|        542|      172.0|\n",
            "|        553|      210.0|\n",
            "|        560|      160.0|\n",
            "|        504|      127.5|\n",
            "|        554|      200.0|\n",
            "+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2.3 Average Revenue Per Customer\n",
        "avg_revenue_customer = sales_df.groupBy(\"customer_id\").agg(avg(\"revenue\").alias(\"avg_revenue\"))\n",
        "avg_revenue_customer.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_D1-jDHY_V5",
        "outputId": "a5cd5087-0840-4ddb-aa2d-e6c421e2b75c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+-------------+\n",
            "|year|month|monthly_total|\n",
            "+----+-----+-------------+\n",
            "|2025|    9|       2679.0|\n",
            "|2025|    7|       2795.5|\n",
            "|2025|    8|       4136.0|\n",
            "+----+-----+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2.4 Monthly Sales Total\n",
        "monthly_sales = sales_df.withColumn(\"month\", month(\"sale_date\")) \\\n",
        "                        .withColumn(\"year\", year(\"sale_date\")) \\\n",
        "                        .groupBy(\"year\", \"month\").agg(sum(\"revenue\").alias(\"monthly_total\"))\n",
        "monthly_sales.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0jC-6eoZDW-",
        "outputId": "d3ac7840-9096-490e-d640-c99c767f2d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----------+\n",
            "|     category|sales_count|\n",
            "+-------------+-----------+\n",
            "|  Electronics|         16|\n",
            "|    Furniture|         18|\n",
            "|      Gadgets|         21|\n",
            "|Home & Living|         15|\n",
            "+-------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2.5 Count of Sales Per Category\n",
        "sales_with_category = sales_df.join(product_df, \"product_id\")\n",
        "category_count = sales_with_category.groupBy(\"category\").agg(count(\"*\").alias(\"sales_count\"))\n",
        "category_count.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRfcnw8OZIiL",
        "outputId": "16ef5c18-bf9d-459e-a936-c39cb5e8b00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------------+\n",
            "|product_id|total_revenue|\n",
            "+----------+-------------+\n",
            "|       105|        540.0|\n",
            "|       106|        520.0|\n",
            "|       115|        484.0|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2.6 Top 3 Most Expensive Products Sold (By Revenue)\n",
        "revenue_product = sales_df.groupBy(\"product_id\").agg(sum(\"revenue\").alias(\"total_revenue\"))\n",
        "top3_products = revenue_product.orderBy(desc(\"total_revenue\")).limit(3)\n",
        "top3_products.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpJs6EfRZLMl",
        "outputId": "b0444fc2-0722-4ad9-af83-124e3d3c83a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "|product_id|sale_id|customer_id|          sale_date|quantity|price|revenue|product_name|     category|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "|       101|   1001|        501|2025-07-10 08:23:00|       3| 25.5|   76.5|    Widget A|      Gadgets|\n",
            "|       102|   1002|        502|2025-07-11 09:45:00|       2| 15.0|   30.0|    Widget B|      Gadgets|\n",
            "|       103|   1003|        503|2025-07-12 10:15:00|       1| 30.0|   30.0|    Widget C|  Electronics|\n",
            "|       101|   1004|        504|2025-07-13 12:20:00|       5| 25.5|  127.5|    Widget A|      Gadgets|\n",
            "|       105|   1005|        505|2025-07-14 14:35:00|      10| 45.0|  450.0|    Widget E|Home & Living|\n",
            "|       102|   1006|        506|2025-07-15 16:00:00|       4| 15.0|   60.0|    Widget B|      Gadgets|\n",
            "|       106|   1007|        507|2025-07-16 17:10:00|       3| 40.0|  120.0|    Widget F|Home & Living|\n",
            "|       107|   1008|        508|2025-07-17 18:25:00|       2| 60.0|  120.0|    Widget G|    Furniture|\n",
            "|       108|   1009|        509|2025-07-18 19:30:00|       7| 25.0|  175.0|    Widget H|      Gadgets|\n",
            "|       109|   1010|        510|2025-07-19 20:45:00|       6| 50.0|  300.0|    Widget I|    Furniture|\n",
            "|       110|   1011|        511|2025-07-20 21:55:00|       4| 12.5|   50.0|    Widget J|  Electronics|\n",
            "|       111|   1012|        512|2025-07-21 22:30:00|       9| 10.0|   90.0|    Widget K|Home & Living|\n",
            "|       112|   1013|        513|2025-07-22 23:40:00|       8| 22.5|  180.0|    Widget L|  Electronics|\n",
            "|       113|   1014|        514|2025-07-23 09:15:00|       3| 17.0|   51.0|    Widget M|      Gadgets|\n",
            "|       114|   1015|        515|2025-07-24 10:35:00|       2| 45.5|   91.0|    Widget N|    Furniture|\n",
            "|       115|   1016|        516|2025-07-25 11:45:00|       4| 32.0|  128.0|    Widget O|      Gadgets|\n",
            "|       116|   1017|        517|2025-07-26 13:00:00|       5| 28.0|  140.0|    Widget P|Home & Living|\n",
            "|       117|   1018|        518|2025-07-27 14:15:00|       1| 50.0|   50.0|    Widget Q|  Electronics|\n",
            "|       118|   1019|        519|2025-07-28 15:30:00|       6| 18.5|  111.0|    Widget R|    Furniture|\n",
            "|       119|   1020|        520|2025-07-29 16:45:00|       7| 40.0|  280.0|    Widget S|      Gadgets|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. Joins\n",
        "# 3.1 Sales with Product Information\n",
        "sales_product = sales_df.join(product_df, \"product_id\")\n",
        "sales_product.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmuJTPcOZXGs",
        "outputId": "2dc7325c-bf02-4ec1-eab4-13a38f09d092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------+----------+-------------------+--------+-----+-------+-------------+-------------------+-------------------+\n",
            "|customer_id|sale_id|product_id|          sale_date|quantity|price|revenue|customer_name|              email|          join_date|\n",
            "+-----------+-------+----------+-------------------+--------+-----+-------+-------------+-------------------+-------------------+\n",
            "|        501|   1001|       101|2025-07-10 08:23:00|       3| 25.5|   76.5|        Alice|  alice@example.com|2025-05-20 10:10:00|\n",
            "|        502|   1002|       102|2025-07-11 09:45:00|       2| 15.0|   30.0|          Bob|    bob@example.com|2025-06-15 14:00:00|\n",
            "|        503|   1003|       103|2025-07-12 10:15:00|       1| 30.0|   30.0|      Charlie|charlie@example.com|2025-04-05 09:50:00|\n",
            "|        504|   1004|       101|2025-07-13 12:20:00|       5| 25.5|  127.5|        David|  david@example.com|2025-07-01 12:25:00|\n",
            "|        505|   1005|       105|2025-07-14 14:35:00|      10| 45.0|  450.0|         Emma|   emma@example.com|2025-07-10 15:30:00|\n",
            "|        506|   1006|       102|2025-07-15 16:00:00|       4| 15.0|   60.0|        Frank|  frank@example.com|2025-03-23 17:00:00|\n",
            "|        507|   1007|       106|2025-07-16 17:10:00|       3| 40.0|  120.0|        Grace|  grace@example.com|2025-05-01 13:20:00|\n",
            "|        508|   1008|       107|2025-07-17 18:25:00|       2| 60.0|  120.0|        Henry|  henry@example.com|2025-06-07 10:10:00|\n",
            "|        509|   1009|       108|2025-07-18 19:30:00|       7| 25.0|  175.0|       Isabel| isabel@example.com|2025-05-25 16:30:00|\n",
            "|        510|   1010|       109|2025-07-19 20:45:00|       6| 50.0|  300.0|         Jack|   jack@example.com|2025-04-12 11:55:00|\n",
            "|        511|   1011|       110|2025-07-20 21:55:00|       4| 12.5|   50.0|         Kate|   kate@example.com|2025-06-18 14:10:00|\n",
            "|        512|   1012|       111|2025-07-21 22:30:00|       9| 10.0|   90.0|         Liam|   liam@example.com|2025-07-05 08:45:00|\n",
            "|        513|   1013|       112|2025-07-22 23:40:00|       8| 22.5|  180.0|         Mona|   mona@example.com|2025-03-30 15:25:00|\n",
            "|        514|   1014|       113|2025-07-23 09:15:00|       3| 17.0|   51.0|         Nina|   nina@example.com|2025-04-19 10:35:00|\n",
            "|        515|   1015|       114|2025-07-24 10:35:00|       2| 45.5|   91.0|        Oscar|  oscar@example.com|2025-05-14 09:15:00|\n",
            "|        516|   1016|       115|2025-07-25 11:45:00|       4| 32.0|  128.0|         Paul|   paul@example.com|2025-06-03 12:50:00|\n",
            "|        517|   1017|       116|2025-07-26 13:00:00|       5| 28.0|  140.0|        Quinn|  quinn@example.com|2025-07-13 13:10:00|\n",
            "|        518|   1018|       117|2025-07-27 14:15:00|       1| 50.0|   50.0|         Rita|   rita@example.com|2025-07-20 11:00:00|\n",
            "|        519|   1019|       118|2025-07-28 15:30:00|       6| 18.5|  111.0|         Sara|   sara@example.com|2025-06-30 17:40:00|\n",
            "|        520|   1020|       119|2025-07-29 16:45:00|       7| 40.0|  280.0|          Tom|    tom@example.com|2025-05-18 14:20:00|\n",
            "+-----------+-------+----------+-------------------+--------+-----+-------+-------------+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.2 Join Sales with Customer Information\n",
        "sales_customer = sales_df.join(customer_df, \"customer_id\")\n",
        "sales_customer.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyHD_h6zZ3VR",
        "outputId": "44fcaa80-0503-4cf2-a549-f4a64892dc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+--------+\n",
            "|product_id|sale_id|customer_id|          sale_date|quantity|price|revenue|product_name|category|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+--------+\n",
            "|       101|   1001|        501|2025-07-10 08:23:00|       3| 25.5|   76.5|    Widget A| Gadgets|\n",
            "|       102|   1002|        502|2025-07-11 09:45:00|       2| 15.0|   30.0|    Widget B| Gadgets|\n",
            "|       101|   1004|        504|2025-07-13 12:20:00|       5| 25.5|  127.5|    Widget A| Gadgets|\n",
            "|       102|   1006|        506|2025-07-15 16:00:00|       4| 15.0|   60.0|    Widget B| Gadgets|\n",
            "|       108|   1009|        509|2025-07-18 19:30:00|       7| 25.0|  175.0|    Widget H| Gadgets|\n",
            "|       113|   1014|        514|2025-07-23 09:15:00|       3| 17.0|   51.0|    Widget M| Gadgets|\n",
            "|       115|   1016|        516|2025-07-25 11:45:00|       4| 32.0|  128.0|    Widget O| Gadgets|\n",
            "|       119|   1020|        520|2025-07-29 16:45:00|       7| 40.0|  280.0|    Widget S| Gadgets|\n",
            "|       125|   1026|        526|2025-08-04 22:25:00|       8| 33.0|  264.0|    Widget Y| Gadgets|\n",
            "|       128|   1029|        529|2025-08-07 10:10:00|       4| 22.5|   90.0|   Widget AB| Gadgets|\n",
            "|       131|   1032|        532|2025-08-10 13:30:00|       8| 29.5|  236.0|   Widget AE| Gadgets|\n",
            "|       137|   1038|        538|2025-08-16 19:00:00|       5| 23.0|  115.0|   Widget AK| Gadgets|\n",
            "|       141|   1042|        542|2025-08-20 23:10:00|       8| 21.5|  172.0|   Widget AO| Gadgets|\n",
            "|       144|   1045|        545|2025-08-23 11:40:00|       3| 30.5|   91.5|   Widget AR| Gadgets|\n",
            "|       149|   1050|        550|2025-08-28 16:50:00|       1| 50.0|   50.0|   Widget AW| Gadgets|\n",
            "|       101|   1051|        551|2025-08-29 17:55:00|       3| 25.5|   76.5|    Widget A| Gadgets|\n",
            "|       102|   1052|        552|2025-08-30 18:45:00|       4| 15.0|   60.0|    Widget B| Gadgets|\n",
            "|       108|   1058|        558|2025-09-05 09:30:00|       1| 60.0|   60.0|    Widget H| Gadgets|\n",
            "|       113|   1063|        563|2025-09-10 15:25:00|       7| 38.0|  266.0|    Widget M| Gadgets|\n",
            "|       115|   1065|        565|2025-09-12 17:45:00|       8| 44.5|  356.0|    Widget O| Gadgets|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.3 Inner Join Between Sales and Products (Only \"Gadgets\")\n",
        "gadgets_sales = sales_df.join(product_df, \"product_id\") \\\n",
        "                        .filter(col(\"category\") == \"Gadgets\")\n",
        "gadgets_sales.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA60QFX-Z8cT",
        "outputId": "0b75c07d-a7c4-4f23-b66b-c29e391bed58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "|product_id|sale_id|customer_id|          sale_date|quantity|price|revenue|product_name|     category|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "|       101|   1001|        501|2025-07-10 08:23:00|       3| 25.5|   76.5|    Widget A|      Gadgets|\n",
            "|       102|   1002|        502|2025-07-11 09:45:00|       2| 15.0|   30.0|    Widget B|      Gadgets|\n",
            "|       103|   1003|        503|2025-07-12 10:15:00|       1| 30.0|   30.0|    Widget C|  Electronics|\n",
            "|       101|   1004|        504|2025-07-13 12:20:00|       5| 25.5|  127.5|    Widget A|      Gadgets|\n",
            "|       105|   1005|        505|2025-07-14 14:35:00|      10| 45.0|  450.0|    Widget E|Home & Living|\n",
            "|       102|   1006|        506|2025-07-15 16:00:00|       4| 15.0|   60.0|    Widget B|      Gadgets|\n",
            "|       106|   1007|        507|2025-07-16 17:10:00|       3| 40.0|  120.0|    Widget F|Home & Living|\n",
            "|       107|   1008|        508|2025-07-17 18:25:00|       2| 60.0|  120.0|    Widget G|    Furniture|\n",
            "|       108|   1009|        509|2025-07-18 19:30:00|       7| 25.0|  175.0|    Widget H|      Gadgets|\n",
            "|       109|   1010|        510|2025-07-19 20:45:00|       6| 50.0|  300.0|    Widget I|    Furniture|\n",
            "|       110|   1011|        511|2025-07-20 21:55:00|       4| 12.5|   50.0|    Widget J|  Electronics|\n",
            "|       111|   1012|        512|2025-07-21 22:30:00|       9| 10.0|   90.0|    Widget K|Home & Living|\n",
            "|       112|   1013|        513|2025-07-22 23:40:00|       8| 22.5|  180.0|    Widget L|  Electronics|\n",
            "|       113|   1014|        514|2025-07-23 09:15:00|       3| 17.0|   51.0|    Widget M|      Gadgets|\n",
            "|       114|   1015|        515|2025-07-24 10:35:00|       2| 45.5|   91.0|    Widget N|    Furniture|\n",
            "|       115|   1016|        516|2025-07-25 11:45:00|       4| 32.0|  128.0|    Widget O|      Gadgets|\n",
            "|       116|   1017|        517|2025-07-26 13:00:00|       5| 28.0|  140.0|    Widget P|Home & Living|\n",
            "|       117|   1018|        518|2025-07-27 14:15:00|       1| 50.0|   50.0|    Widget Q|  Electronics|\n",
            "|       118|   1019|        519|2025-07-28 15:30:00|       6| 18.5|  111.0|    Widget R|    Furniture|\n",
            "|       119|   1020|        520|2025-07-29 16:45:00|       7| 40.0|  280.0|    Widget S|      Gadgets|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.4 Left Join Between Sales and Products\n",
        "left_join_df = sales_df.join(product_df, \"product_id\", \"left\")\n",
        "left_join_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6qLzbcnaEtI",
        "outputId": "ae5637c1-4975-49ca-a6fc-a84b4913a51e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------------+-------------------+----------+\n",
            "|sale_id|          sale_date|          sale_date|product_id|\n",
            "+-------+-------------------+-------------------+----------+\n",
            "|   1001|2025-07-10 08:23:00|2025-08-29 17:55:00|       101|\n",
            "|   1001|2025-07-10 08:23:00|2025-07-13 12:20:00|       101|\n",
            "|   1002|2025-07-11 09:45:00|2025-08-30 18:45:00|       102|\n",
            "|   1002|2025-07-11 09:45:00|2025-07-15 16:00:00|       102|\n",
            "|   1003|2025-07-12 10:15:00|2025-08-31 19:30:00|       103|\n",
            "|   1004|2025-07-13 12:20:00|2025-08-29 17:55:00|       101|\n",
            "|   1005|2025-07-14 14:35:00|2025-09-02 21:10:00|       105|\n",
            "|   1006|2025-07-15 16:00:00|2025-08-30 18:45:00|       102|\n",
            "|   1007|2025-07-16 17:10:00|2025-09-03 22:30:00|       106|\n",
            "|   1008|2025-07-17 18:25:00|2025-09-04 23:50:00|       107|\n",
            "|   1009|2025-07-18 19:30:00|2025-09-05 09:30:00|       108|\n",
            "|   1010|2025-07-19 20:45:00|2025-09-06 10:40:00|       109|\n",
            "|   1011|2025-07-20 21:55:00|2025-09-07 11:50:00|       110|\n",
            "|   1012|2025-07-21 22:30:00|2025-09-08 13:00:00|       111|\n",
            "|   1013|2025-07-22 23:40:00|2025-09-09 14:10:00|       112|\n",
            "|   1014|2025-07-23 09:15:00|2025-09-10 15:25:00|       113|\n",
            "|   1015|2025-07-24 10:35:00|2025-09-11 16:35:00|       114|\n",
            "|   1016|2025-07-25 11:45:00|2025-09-12 17:45:00|       115|\n",
            "|   1017|2025-07-26 13:00:00|2025-09-13 18:55:00|       116|\n",
            "|   1018|2025-07-27 14:15:00|2025-09-14 20:00:00|       117|\n",
            "+-------+-------------------+-------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.5 Self-Join Sales Table on Same Product (Different Date)\n",
        "sales_self_join = sales_df.alias(\"s1\").join(\n",
        "    sales_df.alias(\"s2\"),\n",
        "    (col(\"s1.product_id\") == col(\"s2.product_id\")) & (col(\"s1.sale_date\") < col(\"s2.sale_date\"))\n",
        ")\n",
        "sales_self_join.select(\"s1.sale_id\", \"s1.sale_date\", \"s2.sale_date\", \"s1.product_id\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W1I-HZqaJsJ",
        "outputId": "d8acb2aa-15a5-4747-ff20-726449c3b522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "|product_id|sale_id|customer_id|          sale_date|quantity|price|revenue|product_name|     category|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "|       101|   1001|        501|2025-07-10 08:23:00|       3| 25.5|   76.5|    Widget A|      Gadgets|\n",
            "|       101|   1004|        504|2025-07-13 12:20:00|       5| 25.5|  127.5|    Widget A|      Gadgets|\n",
            "|       101|   1051|        551|2025-08-29 17:55:00|       3| 25.5|   76.5|    Widget A|      Gadgets|\n",
            "|       102|   1002|        502|2025-07-11 09:45:00|       2| 15.0|   30.0|    Widget B|      Gadgets|\n",
            "|       102|   1006|        506|2025-07-15 16:00:00|       4| 15.0|   60.0|    Widget B|      Gadgets|\n",
            "|       102|   1052|        552|2025-08-30 18:45:00|       4| 15.0|   60.0|    Widget B|      Gadgets|\n",
            "|       103|   1003|        503|2025-07-12 10:15:00|       1| 30.0|   30.0|    Widget C|  Electronics|\n",
            "|       103|   1053|        553|2025-08-31 19:30:00|       7| 30.0|  210.0|    Widget C|  Electronics|\n",
            "|       104|   1054|        554|2025-09-01 20:40:00|       5| 40.0|  200.0|    Widget D|  Electronics|\n",
            "|       105|   1005|        505|2025-07-14 14:35:00|      10| 45.0|  450.0|    Widget E|Home & Living|\n",
            "|       105|   1055|        555|2025-09-02 21:10:00|       2| 45.0|   90.0|    Widget E|Home & Living|\n",
            "|       106|   1007|        507|2025-07-16 17:10:00|       3| 40.0|  120.0|    Widget F|Home & Living|\n",
            "|       106|   1056|        556|2025-09-03 22:30:00|       8| 50.0|  400.0|    Widget F|Home & Living|\n",
            "|       107|   1008|        508|2025-07-17 18:25:00|       2| 60.0|  120.0|    Widget G|    Furniture|\n",
            "|       107|   1057|        557|2025-09-04 23:50:00|       3| 20.5|   61.5|    Widget G|    Furniture|\n",
            "|       108|   1009|        509|2025-07-18 19:30:00|       7| 25.0|  175.0|    Widget H|      Gadgets|\n",
            "|       108|   1058|        558|2025-09-05 09:30:00|       1| 60.0|   60.0|    Widget H|      Gadgets|\n",
            "|       109|   1010|        510|2025-07-19 20:45:00|       6| 50.0|  300.0|    Widget I|    Furniture|\n",
            "|       109|   1059|        559|2025-09-06 10:40:00|       6| 18.0|  108.0|    Widget I|    Furniture|\n",
            "|       110|   1011|        511|2025-07-20 21:55:00|       4| 12.5|   50.0|    Widget J|  Electronics|\n",
            "+----------+-------+-----------+-------------------+--------+-----+-------+------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.6 Full Outer Join Sales and Products\n",
        "full_outer = sales_df.join(product_df, \"product_id\", \"outer\")\n",
        "full_outer.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75LcawU9aN_P",
        "outputId": "71478441-29a3-470a-ae84-2e78d7e58c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------------+------------+-------------+-------+\n",
            "|sale_id|customer_name|product_name|     category|revenue|\n",
            "+-------+-------------+------------+-------------+-------+\n",
            "|   1001|        Alice|    Widget A|      Gadgets|   76.5|\n",
            "|   1002|          Bob|    Widget B|      Gadgets|   30.0|\n",
            "|   1003|      Charlie|    Widget C|  Electronics|   30.0|\n",
            "|   1004|        David|    Widget A|      Gadgets|  127.5|\n",
            "|   1005|         Emma|    Widget E|Home & Living|  450.0|\n",
            "|   1006|        Frank|    Widget B|      Gadgets|   60.0|\n",
            "|   1007|        Grace|    Widget F|Home & Living|  120.0|\n",
            "|   1008|        Henry|    Widget G|    Furniture|  120.0|\n",
            "|   1009|       Isabel|    Widget H|      Gadgets|  175.0|\n",
            "|   1010|         Jack|    Widget I|    Furniture|  300.0|\n",
            "|   1011|         Kate|    Widget J|  Electronics|   50.0|\n",
            "|   1012|         Liam|    Widget K|Home & Living|   90.0|\n",
            "|   1013|         Mona|    Widget L|  Electronics|  180.0|\n",
            "|   1014|         Nina|    Widget M|      Gadgets|   51.0|\n",
            "|   1015|        Oscar|    Widget N|    Furniture|   91.0|\n",
            "|   1016|         Paul|    Widget O|      Gadgets|  128.0|\n",
            "|   1017|        Quinn|    Widget P|Home & Living|  140.0|\n",
            "|   1018|         Rita|    Widget Q|  Electronics|   50.0|\n",
            "|   1019|         Sara|    Widget R|    Furniture|  111.0|\n",
            "|   1020|          Tom|    Widget S|      Gadgets|  280.0|\n",
            "+-------+-------------+------------+-------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3.7 Join Multiple Tables (Sales + Customer + Product)\n",
        "complete_view = sales_df.join(customer_df, \"customer_id\") \\\n",
        "                        .join(product_df, \"product_id\")\n",
        "complete_view.select(\"sale_id\", \"customer_name\", \"product_name\", \"category\", \"revenue\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SgAyqHOaSyr",
        "outputId": "194748f7-9024-41c5-bdc0-5c7b4615c8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------+-----------+-------------------+--------+-----+-------+\n",
            "|sale_id|product_id|customer_id|          sale_date|quantity|price|revenue|\n",
            "+-------+----------+-----------+-------------------+--------+-----+-------+\n",
            "|   1001|       101|        501|2025-07-10 08:23:00|       3| 25.5|   76.5|\n",
            "|   1002|       102|        502|2025-07-11 09:45:00|       2| 15.0|   30.0|\n",
            "|   1003|       103|        503|2025-07-12 10:15:00|       1| 30.0|   30.0|\n",
            "|   1004|       101|        504|2025-07-13 12:20:00|       5| 25.5|  127.5|\n",
            "|   1005|       105|        505|2025-07-14 14:35:00|      10| 45.0|  450.0|\n",
            "+-------+----------+-----------+-------------------+--------+-----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4. Transformations\n",
        "# 4.1 Filter Data for Specific Date Range\n",
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "filtered_sales = sales_df.filter((col(\"sale_date\") >= \"2025-07-10\") & (col(\"sale_date\") <= \"2025-07-15\"))\n",
        "filtered_sales.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t8gKhG2ahGg",
        "outputId": "67c240a3-a708-4970-d8cb-ddf964bef916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+\n",
            "|customer_id|total_spent|\n",
            "+-----------+-----------+\n",
            "|        505|      450.0|\n",
            "|        556|      400.0|\n",
            "|        565|      356.0|\n",
            "|        510|      300.0|\n",
            "|        520|      280.0|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4.2 Top 5 Customers by Total Spend\n",
        "top_customers = sales_df.groupBy(\"customer_id\").agg(sum(\"revenue\").alias(\"total_spent\")) \\\n",
        "                        .orderBy(desc(\"total_spent\")).limit(5)\n",
        "top_customers.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r55j7-1xamP6",
        "outputId": "000c5da9-0554-43de-c53c-38ce1e1bdd17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+--------------+\n",
            "|customer_id|total_spent|spend_category|\n",
            "+-----------+-----------+--------------+\n",
            "|        540|       55.5|           Low|\n",
            "|        516|      128.0|        Medium|\n",
            "|        513|      180.0|        Medium|\n",
            "|        530|       76.0|           Low|\n",
            "|        501|       76.5|           Low|\n",
            "|        548|      198.0|        Medium|\n",
            "|        539|      210.0|        Medium|\n",
            "|        519|      111.0|        Medium|\n",
            "|        556|      400.0|          High|\n",
            "|        512|       90.0|           Low|\n",
            "|        570|      120.0|        Medium|\n",
            "|        559|      108.0|        Medium|\n",
            "|        545|       91.5|           Low|\n",
            "|        507|      120.0|        Medium|\n",
            "|        544|       84.0|           Low|\n",
            "|        542|      172.0|        Medium|\n",
            "|        553|      210.0|        Medium|\n",
            "|        560|      160.0|        Medium|\n",
            "|        504|      127.5|        Medium|\n",
            "|        554|      200.0|        Medium|\n",
            "+-----------+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4.3 Categorize Customers Based on Spend\n",
        "spend_df = sales_df.groupBy(\"customer_id\").agg(sum(\"revenue\").alias(\"total_spent\"))\n",
        "\n",
        "spend_categorized = spend_df.withColumn(\"spend_category\",\n",
        "    when(col(\"total_spent\") < 100, \"Low\")\n",
        "    .when(col(\"total_spent\") < 300, \"Medium\")\n",
        "    .otherwise(\"High\")\n",
        ")\n",
        "spend_categorized.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGVD-tCbarEg",
        "outputId": "8976ce36-6f2d-4384-de04-3ed3452f4144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------------+-------------------+\n",
            "|customer_id|     first_purchase|      last_purchase|\n",
            "+-----------+-------------------+-------------------+\n",
            "|        540|2025-08-18 21:25:00|2025-08-18 21:25:00|\n",
            "|        516|2025-07-25 11:45:00|2025-07-25 11:45:00|\n",
            "|        513|2025-07-22 23:40:00|2025-07-22 23:40:00|\n",
            "|        530|2025-08-08 11:00:00|2025-08-08 11:00:00|\n",
            "|        501|2025-07-10 08:23:00|2025-07-10 08:23:00|\n",
            "|        548|2025-08-26 14:25:00|2025-08-26 14:25:00|\n",
            "|        539|2025-08-17 20:15:00|2025-08-17 20:15:00|\n",
            "|        519|2025-07-28 15:30:00|2025-07-28 15:30:00|\n",
            "|        556|2025-09-03 22:30:00|2025-09-03 22:30:00|\n",
            "|        512|2025-07-21 22:30:00|2025-07-21 22:30:00|\n",
            "|        570|2025-09-17 23:00:00|2025-09-17 23:00:00|\n",
            "|        559|2025-09-06 10:40:00|2025-09-06 10:40:00|\n",
            "|        545|2025-08-23 11:40:00|2025-08-23 11:40:00|\n",
            "|        507|2025-07-16 17:10:00|2025-07-16 17:10:00|\n",
            "|        544|2025-08-22 10:30:00|2025-08-22 10:30:00|\n",
            "|        542|2025-08-20 23:10:00|2025-08-20 23:10:00|\n",
            "|        553|2025-08-31 19:30:00|2025-08-31 19:30:00|\n",
            "|        560|2025-09-07 11:50:00|2025-09-07 11:50:00|\n",
            "|        504|2025-07-13 12:20:00|2025-07-13 12:20:00|\n",
            "|        554|2025-09-01 20:40:00|2025-09-01 20:40:00|\n",
            "+-----------+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4.4 First and Last Purchase for Each Customer\n",
        "first_last = sales_df.groupBy(\"customer_id\").agg(\n",
        "    min(\"sale_date\").alias(\"first_purchase\"),\n",
        "    max(\"sale_date\").alias(\"last_purchase\")\n",
        ")\n",
        "first_last.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH_U-4kvavaM",
        "outputId": "efa052a6-48e5-49d9-a0b2-5babb0f00a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-------------------+\n",
            "|customer_id|      last_purchase|\n",
            "+-----------+-------------------+\n",
            "|        516|2025-07-25 11:45:00|\n",
            "|        513|2025-07-22 23:40:00|\n",
            "|        530|2025-08-08 11:00:00|\n",
            "|        501|2025-07-10 08:23:00|\n",
            "|        539|2025-08-17 20:15:00|\n",
            "|        519|2025-07-28 15:30:00|\n",
            "|        512|2025-07-21 22:30:00|\n",
            "|        507|2025-07-16 17:10:00|\n",
            "|        504|2025-07-13 12:20:00|\n",
            "|        511|2025-07-20 21:55:00|\n",
            "|        502|2025-07-11 09:45:00|\n",
            "|        523|2025-08-01 19:00:00|\n",
            "|        531|2025-08-09 12:20:00|\n",
            "|        505|2025-07-14 14:35:00|\n",
            "|        538|2025-08-16 19:00:00|\n",
            "|        503|2025-07-12 10:15:00|\n",
            "|        537|2025-08-15 18:30:00|\n",
            "|        520|2025-07-29 16:45:00|\n",
            "|        514|2025-07-23 09:15:00|\n",
            "|        532|2025-08-10 13:30:00|\n",
            "+-----------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4.5 Customer Churn (No Purchase in Last 30 Days)\n",
        "from pyspark.sql.functions import current_date, datediff\n",
        "\n",
        "# Assume latest sale date from data\n",
        "latest_sale_date = sales_df.agg(max(\"sale_date\")).collect()[0][0]\n",
        "\n",
        "churn_df = sales_df.groupBy(\"customer_id\").agg(max(\"sale_date\").alias(\"last_purchase\"))\n",
        "churned_customers = churn_df.filter(datediff(lit(latest_sale_date), col(\"last_purchase\")) > 30)\n",
        "churned_customers.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBmRIxh6ai3G"
      },
      "source": [
        "## Adv. PySpark(Window Functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pX62A5japKb",
        "outputId": "e3873720-7d9c-4067-e971-639f63f40c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------+------+------------------------+---------------------------+\n",
            "|id |name   |salary|subjects                |address                    |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "|1  |Alice  |2000  |[math, science]         |{zip -> 10001, city -> NYC}|\n",
            "|2  |Bob    |1500  |[english]               |{zip -> 94105, city -> SF} |\n",
            "|3  |Charlie|2200  |[math, history, science]|{zip -> 10001, city -> NYC}|\n",
            "|4  |David  |1200  |[art]                   |{zip -> 90001, city -> LA} |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", 2000, [\"math\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (2, \"Bob\", 1500, [\"english\"], {\"city\": \"SF\", \"zip\": \"94105\"}),\n",
        "    (3, \"Charlie\", 2200, [\"math\", \"history\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (4, \"David\", 1200, [\"art\"], {\"city\": \"LA\", \"zip\": \"90001\"}),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=[\"id\", \"name\", \"salary\", \"subjects\", \"address\"])\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPtR98eCbBgn",
        "outputId": "e5cd8cde-ba10-42a2-f7a9-d34d428e9eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------+------+--------------------+--------------------+----+\n",
            "| id|   name|salary|            subjects|             address|rank|\n",
            "+---+-------+------+--------------------+--------------------+----+\n",
            "|  4|  David|  1200|               [art]|{zip -> 90001, ci...|   1|\n",
            "|  1|  Alice|  2000|     [math, science]|{zip -> 10001, ci...|   1|\n",
            "|  3|Charlie|  2200|[math, history, s...|{zip -> 10001, ci...|   2|\n",
            "|  2|    Bob|  1500|           [english]|{zip -> 94105, ci...|   1|\n",
            "+---+-------+------+--------------------+--------------------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "window_spec = Window.partitionBy(\"address.city\").orderBy(\"salary\")\n",
        "df.withColumn(\"rank\", rank().over(window_spec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n8hQTWebcbA",
        "outputId": "8b945dcb-61b5-4305-df48-f839c974c077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+\n",
            "|EmpID|  Name|Department|Salary|\n",
            "+-----+------+----------+------+\n",
            "|    1|  John|     Sales|  3000|\n",
            "|    2|  Jane|   Finance|  4000|\n",
            "|    3|  Mike|     Sales|  3500|\n",
            "|    4| Alice|   Finance|  3800|\n",
            "|    5|   Bob|        IT|  4500|\n",
            "|    6|   Tom|     Sales|  3700|\n",
            "|    7| Jerry|   Finance|  4200|\n",
            "|    8|   Sam|        IT|  4700|\n",
            "|    9| Steve|     Sales|  3100|\n",
            "|   10|Rachel|        IT|  4600|\n",
            "+-----+------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, row_number, rank, dense_rank, max, sum, avg\n",
        "\n",
        "# Employee Data\n",
        "data = [\n",
        "    (1, \"John\", \"Sales\", 3000),\n",
        "    (2, \"Jane\", \"Finance\", 4000),\n",
        "    (3, \"Mike\", \"Sales\", 3500),\n",
        "    (4, \"Alice\", \"Finance\", 3800),\n",
        "    (5, \"Bob\", \"IT\", 4500),\n",
        "    (6, \"Tom\", \"Sales\", 3700),\n",
        "    (7, \"Jerry\", \"Finance\", 4200),\n",
        "    (8, \"Sam\", \"IT\", 4700),\n",
        "    (9, \"Steve\", \"Sales\", 3100),\n",
        "    (10, \"Rachel\", \"IT\", 4600)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUl613YedXwO",
        "outputId": "1d98aebe-7adc-4723-b571-0aec2e4fc06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+----+\n",
            "|EmpID|  Name|Department|Salary|Rank|\n",
            "+-----+------+----------+------+----+\n",
            "|    7| Jerry|   Finance|  4200|   1|\n",
            "|    2|  Jane|   Finance|  4000|   2|\n",
            "|    4| Alice|   Finance|  3800|   3|\n",
            "|    8|   Sam|        IT|  4700|   1|\n",
            "|   10|Rachel|        IT|  4600|   2|\n",
            "|    5|   Bob|        IT|  4500|   3|\n",
            "|    6|   Tom|     Sales|  3700|   1|\n",
            "|    3|  Mike|     Sales|  3500|   2|\n",
            "|    9| Steve|     Sales|  3100|   3|\n",
            "|    1|  John|     Sales|  3000|   4|\n",
            "+-----+------+----------+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "windowSpec= Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
        "df.withColumn(\"Rank\", rank().over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMo5CB9FdxJO",
        "outputId": "b524caba-1add-468e-d243-3a2e7d329c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+----------+\n",
            "|EmpID|  Name|Department|Salary|Max_Salary|\n",
            "+-----+------+----------+------+----------+\n",
            "|    2|  Jane|   Finance|  4000|      4200|\n",
            "|    4| Alice|   Finance|  3800|      4200|\n",
            "|    7| Jerry|   Finance|  4200|      4200|\n",
            "|    5|   Bob|        IT|  4500|      4700|\n",
            "|    8|   Sam|        IT|  4700|      4700|\n",
            "|   10|Rachel|        IT|  4600|      4700|\n",
            "|    1|  John|     Sales|  3000|      3700|\n",
            "|    3|  Mike|     Sales|  3500|      3700|\n",
            "|    6|   Tom|     Sales|  3700|      3700|\n",
            "|    9| Steve|     Sales|  3100|      3700|\n",
            "+-----+------+----------+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "windowSpec = Window.partitionBy(\"Department\")\n",
        "df.withColumn(\"Max_Salary\", max(\"Salary\").over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjXs9NJBejI6",
        "outputId": "7f8ea14d-4f01-4e47-eb04-a4bdc13ee39a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+----------+\n",
            "|Department|Max Salary|\n",
            "+----------+----------+\n",
            "|   Finance|      4200|\n",
            "|        IT|      4700|\n",
            "|     Sales|      3700|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#department name and max salary\n",
        "window_spec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
        "\n",
        "df.withColumn(\"Max Salary\", max(\"Salary\").over(window_spec)).select(\"Department\", \"Max Salary\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhcFniHBfO70",
        "outputId": "259613de-2053-4d56-e3ab-125a738c193e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+-----------------+\n",
            "|EmpID|  Name|Department|Salary|Cumulative Salary|\n",
            "+-----+------+----------+------+-----------------+\n",
            "|    4| Alice|   Finance|  3800|             3800|\n",
            "|    2|  Jane|   Finance|  4000|             7800|\n",
            "|    7| Jerry|   Finance|  4200|            12000|\n",
            "|    5|   Bob|        IT|  4500|             4500|\n",
            "|   10|Rachel|        IT|  4600|             9100|\n",
            "|    8|   Sam|        IT|  4700|            13800|\n",
            "|    1|  John|     Sales|  3000|             3000|\n",
            "|    9| Steve|     Sales|  3100|             6100|\n",
            "|    3|  Mike|     Sales|  3500|             9600|\n",
            "|    6|   Tom|     Sales|  3700|            13300|\n",
            "+-----+------+----------+------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "windowSpec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\")).rowsBetween(Window.unboundedPreceding, 0)\n",
        "df.withColumn(\"Cumulative Salary\", sum(\"Salary\").over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR5p-BMJ4USD",
        "outputId": "16c7137e-9742-4c88-e390-ffb1c4f32200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+-----------------+\n",
            "|EmpID|  Name|Department|Salary|Cumulative Salary|\n",
            "+-----+------+----------+------+-----------------+\n",
            "|    4| Alice|   Finance|  3800|             3800|\n",
            "|    2|  Jane|   Finance|  4000|             7800|\n",
            "|    7| Jerry|   Finance|  4200|            12000|\n",
            "|    5|   Bob|        IT|  4500|             4500|\n",
            "|   10|Rachel|        IT|  4600|             9100|\n",
            "|    8|   Sam|        IT|  4700|            13800|\n",
            "|    1|  John|     Sales|  3000|             3000|\n",
            "|    9| Steve|     Sales|  3100|             6100|\n",
            "|    3|  Mike|     Sales|  3500|             9600|\n",
            "|    6|   Tom|     Sales|  3700|            13300|\n",
            "+-----+------+----------+------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col,sum\n",
        "\n",
        "window_base=Window.partitionBy(\"Department\").orderBy(\"Salary\")\n",
        "df.withColumn(\"Cumulative Salary\", sum(\"Salary\").over(window_base)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpE6ehCU5vNr",
        "outputId": "c20e8ff1-7dde-45e8-ead7-11fa40161f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+-----------------+\n",
            "|EmpID|  Name|Department|Salary|Cumulative Salary|\n",
            "+-----+------+----------+------+-----------------+\n",
            "|    2|  Jane|   Finance|  4000|            12000|\n",
            "|    4| Alice|   Finance|  3800|            12000|\n",
            "|    7| Jerry|   Finance|  4200|            12000|\n",
            "|    5|   Bob|        IT|  4500|            13800|\n",
            "|    8|   Sam|        IT|  4700|            13800|\n",
            "|   10|Rachel|        IT|  4600|            13800|\n",
            "|    1|  John|     Sales|  3000|            13300|\n",
            "|    3|  Mike|     Sales|  3500|            13300|\n",
            "|    6|   Tom|     Sales|  3700|            13300|\n",
            "|    9| Steve|     Sales|  3100|            13300|\n",
            "+-----+------+----------+------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "window_full_partition =Window.partitionBy(\"Department\")\n",
        "df.withColumn(\"Cumulative Salary\", sum(\"Salary\").over(window_full_partition)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joHxqXK559jC",
        "outputId": "645e2d75-0e71-4b7b-db2e-ca8c56334908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+----------+------+------------------+\n",
            "|EmpID|  Name|Department|Salary|Salary_CurrentOnly|\n",
            "+-----+------+----------+------+------------------+\n",
            "|    4| Alice|   Finance|  3800|              3800|\n",
            "|    2|  Jane|   Finance|  4000|              4000|\n",
            "|    7| Jerry|   Finance|  4200|              4200|\n",
            "|    5|   Bob|        IT|  4500|              4500|\n",
            "|   10|Rachel|        IT|  4600|              4600|\n",
            "|    8|   Sam|        IT|  4700|              4700|\n",
            "|    1|  John|     Sales|  3000|              3000|\n",
            "|    9| Steve|     Sales|  3100|              3100|\n",
            "|    3|  Mike|     Sales|  3500|              3500|\n",
            "|    6|   Tom|     Sales|  3700|              3700|\n",
            "+-----+------+----------+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "window_base=Window.partitionBy(\"Department\").orderBy(\"Salary\")\n",
        "window_current=window_base.rowsBetween(0,0)\n",
        "df.withColumn(\"Salary_CurrentOnly\", sum(\"Salary\").over(window_current)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU9J2Xj_6zOx",
        "outputId": "ec587ee3-39cb-407c-bdab-ae45500b5268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------+------+------------------------+---------------------------+\n",
            "|id |name   |salary|subjects                |address                    |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "|1  |Alice  |2000  |[math, science]         |{zip -> 10001, city -> NYC}|\n",
            "|2  |Bob    |1500  |[english]               |{zip -> 94105, city -> SF} |\n",
            "|3  |Charlie|2200  |[math, history, science]|{zip -> 10001, city -> NYC}|\n",
            "|4  |David  |1200  |[art]                   |{zip -> 90001, city -> LA} |\n",
            "+---+-------+------+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", 2000, [\"math\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (2, \"Bob\", 1500, [\"english\"], {\"city\": \"SF\", \"zip\": \"94105\"}),\n",
        "    (3, \"Charlie\", 2200, [\"math\", \"history\", \"science\"], {\"city\": \"NYC\", \"zip\": \"10001\"}),\n",
        "    (4, \"David\", 1200, [\"art\"], {\"city\": \"LA\", \"zip\": \"90001\"}),\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=[\"id\", \"name\", \"salary\", \"subjects\", \"address\"])\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXPh1nFz7ivK",
        "outputId": "5b3d6666-cc0f-4b78-900d-ac59b1545f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "| id|   name|salary|            subjects|             address|subject_count|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "|  1|  Alice|  2000|     [math, science]|{zip -> 10001, ci...|            2|\n",
            "|  2|    Bob|  1500|           [english]|{zip -> 94105, ci...|            1|\n",
            "|  3|Charlie|  2200|[math, history, s...|{zip -> 10001, ci...|            3|\n",
            "|  4|  David|  1200|               [art]|{zip -> 90001, ci...|            1|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf\n",
        "@udf(IntegerType())\n",
        "def subject_count(subjects):\n",
        "  return len(subjects)\n",
        "\n",
        "df.withColumn(\"subject_count\", subject_count(df.subjects)).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsMEOh6b898p",
        "outputId": "1be997b3-1029-4fcb-8283-c77731186c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "| id|   name|salary|            subjects|             address|double_salary|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "|  1|  Alice|  2000|     [math, science]|{zip -> 10001, ci...|       4000.0|\n",
            "|  2|    Bob|  1500|           [english]|{zip -> 94105, ci...|       3000.0|\n",
            "|  3|Charlie|  2200|[math, history, s...|{zip -> 10001, ci...|       4400.0|\n",
            "|  4|  David|  1200|               [art]|{zip -> 90001, ci...|       2400.0|\n",
            "+---+-------+------+--------------------+--------------------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "@pandas_udf(DoubleType())\n",
        "def multiply_by_two(s: pd.Series) -> pd.Series:\n",
        "    return s * 2\n",
        "\n",
        "df.withColumn(\"double_salary\",multiply_by_two(df.salary)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnH6nr61-mGX",
        "outputId": "966bf028-e140-46dc-82a8-275ff969545a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+------+\n",
            "| id| name|department|salary|\n",
            "+---+-----+----------+------+\n",
            "|  1|Alice|        HR|  3000|\n",
            "|  2|  Bob|        IT|  4000|\n",
            "|  3|Cathy|        HR|  3500|\n",
            "|  4|David|        IT|  4500|\n",
            "|  5|  Eve|   Finance|  5000|\n",
            "|  6|Frank|   Finance|  4800|\n",
            "+---+-----+----------+------+\n",
            "\n",
            "+----------+-------------+\n",
            "|department|     location|\n",
            "+----------+-------------+\n",
            "|        HR|     New York|\n",
            "|        IT|San Francisco|\n",
            "|   Finance|      Chicago|\n",
            "+----------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Use Case Activities\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from pyspark.sql.functions import col, rank, avg, udf, pandas_udf\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "\n",
        "employees_data = [\n",
        "    (1, \"Alice\", \"HR\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"IT\", 4500),\n",
        "    (5, \"Eve\", \"Finance\", 5000),\n",
        "    (6, \"Frank\", \"Finance\", 4800),\n",
        "]\n",
        "\n",
        "employees_df = spark.createDataFrame(employees_data, [\"id\", \"name\", \"department\", \"salary\"])\n",
        "employees_df.show()\n",
        "\n",
        "departments_data = [\n",
        "    (\"HR\", \"New York\"),\n",
        "    (\"IT\", \"San Francisco\"),\n",
        "    (\"Finance\", \"Chicago\"),\n",
        "]\n",
        "\n",
        "departments_df = spark.createDataFrame(departments_data, [\"department\", \"location\"])\n",
        "departments_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdyGBDfyCg16",
        "outputId": "15d81428-68a3-4aaa-f6ce-b5191e672a7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+------+----+\n",
            "| id| name|department|salary|Rank|\n",
            "+---+-----+----------+------+----+\n",
            "|  5|  Eve|   Finance|  5000|   1|\n",
            "|  6|Frank|   Finance|  4800|   2|\n",
            "|  3|Cathy|        HR|  3500|   1|\n",
            "|  1|Alice|        HR|  3000|   2|\n",
            "|  4|David|        IT|  4500|   1|\n",
            "|  2|  Bob|        IT|  4000|   2|\n",
            "+---+-----+----------+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col\n",
        "\n",
        "windowSpec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
        "\n",
        "ranked_employees_df = employees_df.withColumn(\"Rank\", rank().over(windowSpec))\n",
        "\n",
        "ranked_employees_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eYZuwfLCiyP",
        "outputId": "298ecfd8-4154-453b-f251-2ba2f4a698b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+------+-------------------+\n",
            "| id| name|department|salary|Avg_Salary_Per_Dept|\n",
            "+---+-----+----------+------+-------------------+\n",
            "|  5|  Eve|   Finance|  5000|             4900.0|\n",
            "|  6|Frank|   Finance|  4800|             4900.0|\n",
            "|  1|Alice|        HR|  3000|             3250.0|\n",
            "|  3|Cathy|        HR|  3500|             3250.0|\n",
            "|  2|  Bob|        IT|  4000|             4250.0|\n",
            "|  4|David|        IT|  4500|             4250.0|\n",
            "+---+-----+----------+------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg, col\n",
        "\n",
        "windowSpec = Window.partitionBy(\"department\")\n",
        "\n",
        "avg_salary_df = employees_df.withColumn(\"Avg_Salary_Per_Dept\", avg(\"salary\").over(windowSpec))\n",
        "\n",
        "avg_salary_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mPR-sWAi4zz"
      },
      "source": [
        "## Complex Nested Schemas Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR6AZRG8i8lR",
        "outputId": "90ded952-3c38-46d9-afe3-6064c088f2c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+---------------+\n",
            "|Name|Skills         |\n",
            "+----+---------------+\n",
            "|John|[Python, Java] |\n",
            "|Jane|[SQL, R, Scala]|\n",
            "|Mike|[]             |\n",
            "+----+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AdvancedOps\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (\"John\", [\"Python\", \"Java\"]),\n",
        "    (\"Jane\", [\"SQL\", \"R\", \"Scala\"]),\n",
        "    (\"Mike\", [])\n",
        "]\n",
        "columns = [\"Name\", \"Skills\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icgcOcRakBaA",
        "outputId": "a5580369-acde-45db-9758-026faa15bb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+---------------+------+\n",
            "|Name|         Skills| Skill|\n",
            "+----+---------------+------+\n",
            "|John| [Python, Java]|Python|\n",
            "|John| [Python, Java]|  Java|\n",
            "|Jane|[SQL, R, Scala]|   SQL|\n",
            "|Jane|[SQL, R, Scala]|     R|\n",
            "|Jane|[SQL, R, Scala]| Scala|\n",
            "+----+---------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_exploded = df.withColumn(\"Skill\", explode(df.Skills))\n",
        "df_exploded.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSVaIu2xkGp2"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"people\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJiAe2m0lchs",
        "outputId": "b9ffd00e-0c58-4439-826f-09a88b2a3306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+------+\n",
            "|Name| Skill|\n",
            "+----+------+\n",
            "|John|Python|\n",
            "|John|  Java|\n",
            "|Jane|   SQL|\n",
            "|Jane|     R|\n",
            "|Jane| Scala|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_lateral =spark.sql(\"\"\" Select Name, Skill from people lateral view explode(Skills) as Skill\"\"\")\n",
        "df_lateral.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xze4KjHfywH1"
      },
      "source": [
        "## Pivot and UnPivot operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlp_wI71lseg",
        "outputId": "294a6e51-3a97-4b4e-de7e-a5c3f19acbde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----+-----+\n",
            "| Product|Month|Sales|\n",
            "+--------+-----+-----+\n",
            "|ProductA|  Jan|  100|\n",
            "|ProductA|  Feb|  150|\n",
            "|ProductA|  Mar|  120|\n",
            "|ProductB|  Jan|  200|\n",
            "|ProductB|  Feb|  230|\n",
            "|ProductB|  Mar|  210|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (\"ProductA\", \"Jan\", 100),\n",
        "    (\"ProductA\", \"Feb\", 150),\n",
        "    (\"ProductA\", \"Mar\", 120),\n",
        "    (\"ProductB\", \"Jan\", 200),\n",
        "    (\"ProductB\", \"Feb\", 230),\n",
        "    (\"ProductB\", \"Mar\", 210),\n",
        "]\n",
        "columns = [\"Product\", \"Month\", \"Sales\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmtqn24zySDE",
        "outputId": "5df97283-07b8-4cf8-dccd-9981dfffd003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+---+---+---+\n",
            "| Product|Feb|Jan|Mar|\n",
            "+--------+---+---+---+\n",
            "|ProductB|230|200|210|\n",
            "|ProductA|150|100|120|\n",
            "+--------+---+---+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pivot_df=df.groupBy(\"Product\").pivot(\"Month\").sum(\"Sales\")\n",
        "pivot_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLJeW_4ryfDJ",
        "outputId": "15aa9cf9-0095-4462-90df-cc854ba5d677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----+-----+\n",
            "| Product|Month|Sales|\n",
            "+--------+-----+-----+\n",
            "|ProductB|  Jan|  200|\n",
            "|ProductB|  Feb|  230|\n",
            "|ProductB|  Mar|  210|\n",
            "|ProductA|  Jan|  100|\n",
            "|ProductA|  Feb|  150|\n",
            "|ProductA|  Mar|  120|\n",
            "+--------+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "wide_df = df.groupBy(\"Product\").pivot(\"Month\").sum(\"Sales\")\n",
        "unpivot_df = wide_df.selectExpr(\"Product\",\"stack(3,'Jan',Jan,'Feb',Feb,'Mar',Mar) as (Month,Sales)\")\n",
        "unpivot_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itHBly2t0UCB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeSpKrTIlueJ"
      },
      "source": [
        "## RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfVFnDCQlzyk",
        "outputId": "611c5030-e5d4-4498-ec07-fd1304caba3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 4, 6, 8, 10]\n",
            "[2, 4]\n",
            "15\n",
            "[1, 2, 3, 2, 3, 4, 3, 4, 5]\n",
            "['H', 'e', 'l', 'l', 'o', 'W', 'o', 'r', 'l', 'd']\n",
            "[('even', [2, 4]), ('odd', [1, 3, 5])]\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Get the existing SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "rdd =sc.parallelize([1,2,3,4,5])\n",
        "\n",
        "# Transformation: Map\n",
        "rdd_mapped =rdd.map(lambda x: x*2)\n",
        "print(rdd_mapped.collect())  #output: 2,4,6,8,10\n",
        "\n",
        "# Transformation: Filter\n",
        "rdd_filtered= rdd.filter (lambda x: x%2 ==0)\n",
        "print(rdd_filtered.collect())  #output: 2,4\n",
        "\n",
        "# Transformation: Reduce\n",
        "rdd_reduced = rdd.reduce(lambda x,y: x+y)\n",
        "print(rdd_reduced)  #output: 15\n",
        "\n",
        "# Transformation: Flatmap\n",
        "rdd =sc.parallelize([1,2,3])\n",
        "rdd_flatmapped = rdd.flatMap(lambda x: range(x,x+3))\n",
        "print(rdd_flatmapped.collect())  #output: 1, 2, 3, 2, 3, 4, 3, 4, 5\n",
        "\n",
        "rdd=sc.parallelize([\"Hello\",\"World\"])\n",
        "\n",
        "# Create a list of characters for each string\n",
        "rdd_flat=rdd.flatMap(lambda x: list(x))\n",
        "print(rdd_flat.collect())   #output: 'H', 'e', 'l', 'l', 'o', 'W', 'o', 'r', 'l', 'd'\n",
        "\n",
        "rdd = sc.parallelize([1,2,3,4,5])\n",
        "rdd_group =rdd.groupBy(lambda x: \"even\" if x%2==0 else \"odd\")\n",
        "print([(key, list(value)) for key, value in rdd_group.collect()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsMK-6y07uXV"
      },
      "source": [
        "## DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Vtp1-4mki9",
        "outputId": "9df61712-eadc-4dbc-8ba9-0e1898724db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+------+\n",
            "| ID| Name|Department|Salary|\n",
            "+---+-----+----------+------+\n",
            "|  1| John|        HR|  5000|\n",
            "|  2| Jane|        IT|  8000|\n",
            "|  3| Mike|        IT|  6000|\n",
            "|  4| Sara|   Finance|  7000|\n",
            "|  5|David|        HR|  5500|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (1, \"John\", \"HR\", 5000),\n",
        "    (2, \"Jane\", \"IT\", 8000),\n",
        "    (3, \"Mike\", \"IT\", 6000),\n",
        "    (4, \"Sara\", \"Finance\", 7000),\n",
        "    (5, \"David\", \"HR\", 5500)\n",
        "]\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"DataFrameOperations\").getOrCreate()\n",
        "\n",
        "# Define column names\n",
        "columns = [\"ID\", \"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "# Create a DataFrame from the sample data\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Show the DataFrame\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLiNu3xi7n2Y",
        "outputId": "ef5fdf7c-8208-48c9-c9e1-690ef9af41a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "| Name|Salary|\n",
            "+-----+------+\n",
            "| John|  5000|\n",
            "| Jane|  8000|\n",
            "| Mike|  6000|\n",
            "| Sara|  7000|\n",
            "|David|  5500|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"Name\", \"Salary\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5fqWnku722b",
        "outputId": "6f413c73-6162-449a-ea37-277af84907df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+----------+------+\n",
            "| ID|Name|Department|Salary|\n",
            "+---+----+----------+------+\n",
            "|  2|Jane|        IT|  8000|\n",
            "|  4|Sara|   Finance|  7000|\n",
            "+---+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df[\"Salary\"]>6000).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7P4gqLV8DSv",
        "outputId": "db8be39d-fa8b-4171-ffb4-e0a1adbb4197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+------+-----+\n",
            "| ID| Name|Department|Salary|Bonus|\n",
            "+---+-----+----------+------+-----+\n",
            "|  1| John|        HR|  5000|500.0|\n",
            "|  2| Jane|        IT|  8000|800.0|\n",
            "|  3| Mike|        IT|  6000|600.0|\n",
            "|  4| Sara|   Finance|  7000|700.0|\n",
            "|  5|David|        HR|  5500|550.0|\n",
            "+---+-----+----------+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"Bonus\", df[\"Salary\"]*0.1).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCB3RzED8Rbm",
        "outputId": "1db917c0-f99a-414d-b7dd-59b6c70e2e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+------+\n",
            "| ID| Name|Department|Salary|\n",
            "+---+-----+----------+------+\n",
            "|  1| John|        HR|  5000|\n",
            "|  2| Jane|        IT|  8000|\n",
            "|  3| Mike|        IT|  6000|\n",
            "|  4| Sara|   Finance|  7000|\n",
            "|  5|David|        HR|  5500|\n",
            "+---+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df=df.drop(\"Bonus\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHn3sK6e8e7T",
        "outputId": "7f562224-8d2d-46dc-a806-9f6e37d57d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+----------------+\n",
            "| ID| Name|Department|Salary_After_Tax|\n",
            "+---+-----+----------+----------------+\n",
            "|  1| John|        HR|            5000|\n",
            "|  2| Jane|        IT|            8000|\n",
            "|  3| Mike|        IT|            6000|\n",
            "|  4| Sara|   Finance|            7000|\n",
            "|  5|David|        HR|            5500|\n",
            "+---+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df.withColumnRenamed(\"Salary\", \"Salary_After_Tax\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-u1wFFu8tsv",
        "outputId": "fdd5e133-6d67-49f1-ca83-407dd6097e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---------------------+\n",
            "|Department|avg(Salary_After_Tax)|\n",
            "+----------+---------------------+\n",
            "|        HR|               5250.0|\n",
            "|        IT|               7000.0|\n",
            "|   Finance|               7000.0|\n",
            "+----------+---------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy(\"Department\").avg(\"Salary_After_Tax\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSRFA4BT8zi7",
        "outputId": "3d74a4e7-04e5-4264-d7b1-edb3cc9fac8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|Department|count|\n",
            "+----------+-----+\n",
            "|        HR|    2|\n",
            "|        IT|    2|\n",
            "|   Finance|    1|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy(\"Department\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkafLtMR9RpT",
        "outputId": "471ff436-a94a-4cdf-be7e-1896b2c6a374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+----------------+\n",
            "| ID| Name|Department|Salary_After_Tax|\n",
            "+---+-----+----------+----------------+\n",
            "|  2| Jane|        IT|            8000|\n",
            "|  4| Sara|   Finance|            7000|\n",
            "|  3| Mike|        IT|            6000|\n",
            "|  5|David|        HR|            5500|\n",
            "|  1| John|        HR|            5000|\n",
            "+---+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.sort(df[\"Salary_After_Tax\"].desc()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbLVwOLh9lGW",
        "outputId": "7d4f8e9e-d82f-49b1-842c-91d005808c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+----------+----------------+\n",
            "| ID| Name|Department|Salary_After_Tax|\n",
            "+---+-----+----------+----------------+\n",
            "|  1| John|        HR|            5000|\n",
            "|  5|David|        HR|            5500|\n",
            "|  3| Mike|        IT|            6000|\n",
            "|  4| Sara|   Finance|            7000|\n",
            "|  2| Jane|        IT|            8000|\n",
            "+---+-----+----------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import asc\n",
        "df.sort(df[\"Salary_After_Tax\"].asc()).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhyo3nrb9xxB",
        "outputId": "84499bd2-c927-45af-c308-c4fa2240a4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row(ID=1, Name='John', Department='HR', Salary_After_Tax=5000)\n",
            "Row(ID=2, Name='Jane', Department='IT', Salary_After_Tax=8000)\n",
            "Row(ID=3, Name='Mike', Department='IT', Salary_After_Tax=6000)\n",
            "Row(ID=4, Name='Sara', Department='Finance', Salary_After_Tax=7000)\n",
            "Row(ID=5, Name='David', Department='HR', Salary_After_Tax=5500)\n"
          ]
        }
      ],
      "source": [
        "data_list=df.collect()\n",
        "for row in data_list:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrPE0x54-uqE"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yE79roG-wD6",
        "outputId": "b230dabc-6129-43f8-bb60-666d5a91e1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+---+\n",
            "|name|age|\n",
            "+----+---+\n",
            "| RAJ| 23|\n",
            "|Hari| 21|\n",
            "+----+---+\n",
            "\n",
            "+----+---+\n",
            "|name|age|\n",
            "+----+---+\n",
            "| RAJ| 23|\n",
            "|Hari| 21|\n",
            "+----+---+\n",
            "\n",
            "+----+\n",
            "|name|\n",
            "+----+\n",
            "| RAJ|\n",
            "|Hari|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Get the existing SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "rdd = sc.parallelize([Row(name=\"RAJ\", age=23),Row(name=\"Hari\",age=21)])\n",
        "dataset=spark.createDataFrame(rdd)\n",
        "dataset.show()\n",
        "dataset.filter(col(\"age\") > 20).show()\n",
        "dataset.select(\"name\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3LJrn20ACiD",
        "outputId": "5fc36c2e-608e-4d35-b088-5c4d50d54e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "|    4|David|     Sales|  4500|\n",
            "|    5|  Eva|        IT|  4200|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SparkSQLBasics\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, \"Alice\", \"Sales\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500),\n",
        "    (4, \"David\", \"Sales\", 4500),\n",
        "    (5, \"Eva\", \"IT\", 4200)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW57P3cdCRTm",
        "outputId": "7ad59153-fd1d-45e6-cd0f-bfab5ec0253b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RDD Example [('Alice', 3000), ('Bob', 4000), ('Cathy', 3500), ('David', 4500), ('Eva', 4200)]\n"
          ]
        }
      ],
      "source": [
        "# Convert to RDD\n",
        "rdd=df.rdd\n",
        "print(\"RDD Example\", rdd.map(lambda x: (x.Name,x.Salary)).collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0-zgKwLCmFb",
        "outputId": "65e04bfc-4f7e-4b98-a456-bd8d3947d0e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "| Name|Salary|\n",
            "+-----+------+\n",
            "|Alice|  3000|\n",
            "|  Bob|  4000|\n",
            "|Cathy|  3500|\n",
            "|David|  4500|\n",
            "|  Eva|  4200|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"Name\",\"Salary\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smrf1J2-DI11",
        "outputId": "b67a848b-a095-4bde-ca0e-4ee495e1378b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "|    4|David|     Sales|  4500|\n",
            "|    5|  Eva|        IT|  4200|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.createOrReplaceTempView(\"employees\")\n",
        "\n",
        "strSQL=\"SELECT * FROM employees\"\n",
        "sql_result=spark.sql(strSQL)\n",
        "sql_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExtZZKBvEzeg"
      },
      "source": [
        "## DataFormatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhwFqKUwE2Mg",
        "outputId": "e64be9da-fcd5-4b1a-b2a8-977f3d339c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [\n",
        "    (1, \"Alice\", \"Sales\", 3000),\n",
        "    (2, \"Bob\", \"IT\", 4000),\n",
        "    (3, \"Cathy\", \"HR\", 3500)\n",
        "]\n",
        "columns = [\"EmpID\", \"Name\", \"Department\", \"Salary\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C3kBlaAE22F",
        "outputId": "725a46c6-8265-41c8-af3d-376c6c3e7f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH2G1nt2E8QX"
      },
      "outputs": [],
      "source": [
        "df.write.mode(\"overwrite\").json(\"/content/json_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPpjUBU9FR_W",
        "outputId": "09190edc-6767-4217-d9f2-2bf27f9f7f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "part-00000-865f4dd5-5990-4de9-a8de-704fb48b3d70-c000.json  _SUCCESS\n",
            "part-00001-865f4dd5-5990-4de9-a8de-704fb48b3d70-c000.json\n"
          ]
        }
      ],
      "source": [
        "!ls /content/json_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua9LaxxwFVD0",
        "outputId": "4b0a0f09-5c0f-4ca4-d030-013ffddf09ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"EmpID\":1,\"Name\":\"Alice\",\"Department\":\"Sales\",\"Salary\":3000}\n"
          ]
        }
      ],
      "source": [
        "!cat /content/json_data/part-00000-865f4dd5-5990-4de9-a8de-704fb48b3d70-c000.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvpcvK4qFpQ7",
        "outputId": "209244c4-7835-4f6b-d31b-d920deb4fec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-----+------+\n",
            "|Department|EmpID| Name|Salary|\n",
            "+----------+-----+-----+------+\n",
            "|        IT|    2|  Bob|  4000|\n",
            "|        HR|    3|Cathy|  3500|\n",
            "|     Sales|    1|Alice|  3000|\n",
            "+----------+-----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "json_df =spark.read.json(\"/content/json_data\")\n",
        "json_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i4mWF9JFuPy",
        "outputId": "c0410b26-bd36-4a67-8c35-b27d0fdd4da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    1|Alice|     Sales|  3000|\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "strPath=\"/content/csv_data\"\n",
        "df.write.mode(\"overwrite\").option(\"header\",\"true\").csv(strPath)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9fxNAxxGnWn",
        "outputId": "71bee6c6-14bb-4a80-e4b9-b1650e5b1b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----+----------+------+\n",
            "|EmpID| Name|Department|Salary|\n",
            "+-----+-----+----------+------+\n",
            "|    2|  Bob|        IT|  4000|\n",
            "|    3|Cathy|        HR|  3500|\n",
            "|    1|Alice|     Sales|  3000|\n",
            "+-----+-----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "csv_df=spark.read.option(\"header\",\"true\").csv(strPath)\n",
        "csv_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOW5x8cdGx08"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC05Psnmoaec"
      },
      "source": [
        "## Spark Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSgLsJoToc8p",
        "outputId": "01f97b82-c0a1-433b-b833-e5d00b81bbb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file 'employee_data.csv' has been generated successfully.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "# Generate 30 records with random data\n",
        "names = [\"John\", \"Jane\", \"Mike\", \"Sara\", \"David\", \"Emily\", \"George\", \"Nina\", \"Tom\", \"Anna\"]\n",
        "departments = [\"Sales\", \"IT\", \"HR\", \"Finance\", \"Marketing\"]\n",
        "salaries = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "\n",
        "# Create and open a CSV file for writing\n",
        "with open('employee_data.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header\n",
        "    writer.writerow([\"ID\", \"Name\", \"Department\", \"Salary\"])\n",
        "\n",
        "    # Write the 30 records\n",
        "    for i in range(1, 31):\n",
        "        name = random.choice(names)\n",
        "        department = random.choice(departments)\n",
        "        salary = random.choice(salaries)\n",
        "        writer.writerow([i, name, department, salary])\n",
        "\n",
        "print(\"CSV file 'employee_data.csv' has been generated successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMYMa06kov2Q",
        "outputId": "13d85240-3c91-4a44-a35e-5a8f75cf745f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID,Name,Department,Salary\r\n",
            "1,Anna,IT,10000\r\n",
            "2,Nina,Finance,8000\r\n",
            "3,John,Marketing,5000\r\n",
            "4,George,IT,7000\r\n",
            "5,Nina,Sales,8000\r\n",
            "6,Emily,IT,5000\r\n",
            "7,David,HR,8000\r\n",
            "8,George,Marketing,8000\r\n",
            "9,Jane,Finance,5000\r\n",
            "10,Nina,Marketing,8000\r\n",
            "11,Tom,HR,9000\r\n",
            "12,Sara,Marketing,8000\r\n",
            "13,George,Finance,8000\r\n",
            "14,Anna,HR,8000\r\n",
            "15,Jane,IT,4000\r\n",
            "16,Mike,HR,5000\r\n",
            "17,John,IT,9000\r\n",
            "18,John,Finance,9000\r\n",
            "19,Mike,Sales,6000\r\n",
            "20,Mike,IT,10000\r\n",
            "21,Jane,Sales,9000\r\n",
            "22,Anna,IT,8000\r\n",
            "23,Mike,Finance,3000\r\n",
            "24,Nina,Marketing,5000\r\n",
            "25,Tom,Sales,4000\r\n",
            "26,Jane,Sales,8000\r\n",
            "27,Mike,Sales,5000\r\n",
            "28,Mike,Marketing,10000\r\n",
            "29,Sara,Finance,10000\r\n",
            "30,David,Marketing,5000\r\n"
          ]
        }
      ],
      "source": [
        "!cat /content/employee_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM7IbKm5o5bz",
        "outputId": "0d3e61b0-85f7-45bd-9dd0-2cb8a32506cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".  ..  .config\tcsv_data  employee_data.csv  json_data\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!ls /content/ -a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sufLAnFdpKDp"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/empdata/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70LnEOPxpPFG"
      },
      "outputs": [],
      "source": [
        "!mv /content/employee_data.csv /content/empdata/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay0YOip0pSYh",
        "outputId": "6c7059d6-4a03-4320-e3b5-1209bcf58448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID,Name,Department,Salary\r\n",
            "1,Anna,IT,10000\r\n",
            "2,Nina,Finance,8000\r\n",
            "3,John,Marketing,5000\r\n",
            "4,George,IT,7000\r\n",
            "5,Nina,Sales,8000\r\n",
            "6,Emily,IT,5000\r\n",
            "7,David,HR,8000\r\n",
            "8,George,Marketing,8000\r\n",
            "9,Jane,Finance,5000\r\n",
            "10,Nina,Marketing,8000\r\n",
            "11,Tom,HR,9000\r\n",
            "12,Sara,Marketing,8000\r\n",
            "13,George,Finance,8000\r\n",
            "14,Anna,HR,8000\r\n",
            "15,Jane,IT,4000\r\n",
            "16,Mike,HR,5000\r\n",
            "17,John,IT,9000\r\n",
            "18,John,Finance,9000\r\n",
            "19,Mike,Sales,6000\r\n",
            "20,Mike,IT,10000\r\n",
            "21,Jane,Sales,9000\r\n",
            "22,Anna,IT,8000\r\n",
            "23,Mike,Finance,3000\r\n",
            "24,Nina,Marketing,5000\r\n",
            "25,Tom,Sales,4000\r\n",
            "26,Jane,Sales,8000\r\n",
            "27,Mike,Sales,5000\r\n",
            "28,Mike,Marketing,10000\r\n",
            "29,Sara,Finance,10000\r\n",
            "30,David,Marketing,5000\r\n"
          ]
        }
      ],
      "source": [
        "!cat /content/empdata/employee_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W9XbBTrpcOT",
        "outputId": "0e2ff8f1-5391-469c-f9a1-50db75ac7acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StructType([StructField('EmpID', IntegerType(), True), StructField('Name', StringType(), True), StructField('Department', StringType(), True), StructField('Salary', IntegerType(), True)])\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "schema=StructType()\\\n",
        "        .add(\"EmpID\", IntegerType())\\\n",
        "        .add(\"Name\", StringType())\\\n",
        "        .add(\"Department\", StringType())\\\n",
        "        .add(\"Salary\", IntegerType())\n",
        "print(schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6aeOV7jrrRC"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkStreaming\").getOrCreate()\n",
        "stream_df=spark.readStream \\\n",
        "    .option(\"sep\", \",\") \\\n",
        "    .schema(schema) \\\n",
        "    .csv(\"/content/empdata/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjMChM8csEOr"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import upper\n",
        "transformed_df = stream_df.withColumn(\"NameUPPER\", upper(\"Name\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvHLMUMAsrNh"
      },
      "outputs": [],
      "source": [
        "query =transformed_df.writeStream \\\n",
        "  .outputMode(\"append\") \\\n",
        "  .format(\"console\") \\\n",
        "  .start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q3PunUQtAB_"
      },
      "outputs": [],
      "source": [
        "query.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puYePW5rtB8e",
        "outputId": "bb878340-0f04-4ba4-8d29-1511a12d05a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "employee_data.csv\n"
          ]
        }
      ],
      "source": [
        "!ls /content/empdata/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHgOQreYt40C"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat << EOF >/content/empdata/employee_data2.csv\n",
        "1,John,Sales,3000\n",
        "2,Jane,IT,4000\n",
        "3,Mike,Sales,5000\n",
        "4,Sara,Finance,6000\n",
        "5,David,HR,7000\n",
        "6,Emily,Marketing,6000\n",
        "7,George,HR,4000\n",
        "8,Nina,Sales,5000\n",
        "9,Tom,IT,8000\n",
        "10,Anna,Marketing,3000\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlhM3CUgu1PY",
        "outputId": "cbfc5728-6904-44eb-ec4e-2be8778f334a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1,John,Sales,3000\n",
            "2,Jane,IT,4000\n",
            "3,Mike,Sales,5000\n",
            "4,Sara,Finance,6000\n",
            "5,David,HR,7000\n",
            "6,Emily,Marketing,6000\n",
            "7,George,HR,4000\n",
            "8,Nina,Sales,5000\n",
            "9,Tom,IT,8000\n",
            "10,Anna,Marketing,3000\n"
          ]
        }
      ],
      "source": [
        "!cat /content/empdata/employee_data2.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD1wNxUPvCry"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat << EOF >/content/empdata/employee_data3.csv\n",
        "11,John,IT,7000\n",
        "12,Jane,HR,4000\n",
        "13,Mike,Finance,5000\n",
        "14,Sara,Sales,6000\n",
        "15,David,Marketing,7000\n",
        "16,Emily,Sales,8000\n",
        "17,George,Finance,3000\n",
        "18,Nina,IT,6000\n",
        "19,Tom,Sales,4000\n",
        "20,Anna,HR,5000\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqNcdUbrvNI2",
        "outputId": "c86d22e6-e30f-4682-a0fd-7e1a9c6a0b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11,John,IT,7000\n",
            "12,Jane,HR,4000\n",
            "13,Mike,Finance,5000\n",
            "14,Sara,Sales,6000\n",
            "15,David,Marketing,7000\n",
            "16,Emily,Sales,8000\n",
            "17,George,Finance,3000\n",
            "18,Nina,IT,6000\n",
            "19,Tom,Sales,4000\n",
            "20,Anna,HR,5000\n"
          ]
        }
      ],
      "source": [
        "!cat /content/empdata/employee_data3.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1Q7TWc_vQd8"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat << EOF >/content/empdata/employee_data4.csv\n",
        "21,John,Finance,7000\n",
        "22,Jane,Marketing,6000\n",
        "23,Mike,HR,8000\n",
        "24,Sara,Sales,3000\n",
        "25,David,IT,6000\n",
        "26,Emily,Finance,5000\n",
        "27,George,Marketing,4000\n",
        "28,Nina,HR,7000\n",
        "29,Tom,Finance,5000\n",
        "30,Anna,IT,8000\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8xwBVuQvZXj",
        "outputId": "312bfd83-295e-4e84-cb49-e1871dd5b76b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21,John,Finance,7000\n",
            "22,Jane,Marketing,6000\n",
            "23,Mike,HR,8000\n",
            "24,Sara,Sales,3000\n",
            "25,David,IT,6000\n",
            "26,Emily,Finance,5000\n",
            "27,George,Marketing,4000\n",
            "28,Nina,HR,7000\n",
            "29,Tom,Finance,5000\n",
            "30,Anna,IT,8000\n"
          ]
        }
      ],
      "source": [
        "!cat /content/empdata/employee_data4.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2HQHcWzvd04",
        "outputId": "3bcaf067-3567-441c-f6f0-f19371bacef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"EmpID\":21,\"Name\":\"John\",\"Department\":\"Finance\",\"Salary\":7000}\n",
            "{\"EmpID\":22,\"Name\":\"Jane\",\"Department\":\"Marketing\",\"Salary\":6000}\n",
            "{\"EmpID\":23,\"Name\":\"Mike\",\"Department\":\"HR\",\"Salary\":8000}\n",
            "{\"EmpID\":24,\"Name\":\"Sara\",\"Department\":\"Sales\",\"Salary\":3000}\n",
            "{\"EmpID\":25,\"Name\":\"David\",\"Department\":\"IT\",\"Salary\":6000}\n",
            "{\"EmpID\":26,\"Name\":\"Emily\",\"Department\":\"Finance\",\"Salary\":5000}\n",
            "{\"EmpID\":27,\"Name\":\"George\",\"Department\":\"Marketing\",\"Salary\":4000}\n",
            "{\"EmpID\":28,\"Name\":\"Nina\",\"Department\":\"HR\",\"Salary\":7000}\n",
            "{\"EmpID\":29,\"Name\":\"Tom\",\"Department\":\"Finance\",\"Salary\":5000}\n",
            "{\"EmpID\":30,\"Name\":\"Anna\",\"Department\":\"IT\",\"Salary\":8000}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('/content/empdata/employee_data4.csv', header=None)\n",
        "df.columns = ['EmpID', 'Name', 'Department', 'Salary']\n",
        "\n",
        "# Convert to JSON and display\n",
        "json_output = df.to_json(orient='records', lines=True)\n",
        "print(json_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7UUf1iWxGyI",
        "outputId": "f298c0a3-c9a5-46c3-e230-ffa29bfdadb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"EmpID\":1,\"Name\":\"John\",\"Department\":\"Sales\",\"Salary\":3000}\n",
            "{\"EmpID\":2,\"Name\":\"Jane\",\"Department\":\"IT\",\"Salary\":4000}\n",
            "{\"EmpID\":3,\"Name\":\"Mike\",\"Department\":\"Sales\",\"Salary\":5000}\n",
            "{\"EmpID\":4,\"Name\":\"Sara\",\"Department\":\"Finance\",\"Salary\":6000}\n",
            "{\"EmpID\":5,\"Name\":\"David\",\"Department\":\"HR\",\"Salary\":7000}\n",
            "{\"EmpID\":6,\"Name\":\"Emily\",\"Department\":\"Marketing\",\"Salary\":6000}\n",
            "{\"EmpID\":7,\"Name\":\"George\",\"Department\":\"HR\",\"Salary\":4000}\n",
            "{\"EmpID\":8,\"Name\":\"Nina\",\"Department\":\"Sales\",\"Salary\":5000}\n",
            "{\"EmpID\":9,\"Name\":\"Tom\",\"Department\":\"IT\",\"Salary\":8000}\n",
            "{\"EmpID\":10,\"Name\":\"Anna\",\"Department\":\"Marketing\",\"Salary\":3000}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('/content/empdata/employee_data2.csv', header=None)\n",
        "df.columns = ['EmpID', 'Name', 'Department', 'Salary']\n",
        "\n",
        "# Convert to JSON and display\n",
        "json_output = df.to_json(orient='records', lines=True)\n",
        "print(json_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqWXATYaxM9Q",
        "outputId": "e2590424-2545-4671-8567-367d36df70d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"EmpID\":11,\"Name\":\"John\",\"Department\":\"IT\",\"Salary\":7000}\n",
            "{\"EmpID\":12,\"Name\":\"Jane\",\"Department\":\"HR\",\"Salary\":4000}\n",
            "{\"EmpID\":13,\"Name\":\"Mike\",\"Department\":\"Finance\",\"Salary\":5000}\n",
            "{\"EmpID\":14,\"Name\":\"Sara\",\"Department\":\"Sales\",\"Salary\":6000}\n",
            "{\"EmpID\":15,\"Name\":\"David\",\"Department\":\"Marketing\",\"Salary\":7000}\n",
            "{\"EmpID\":16,\"Name\":\"Emily\",\"Department\":\"Sales\",\"Salary\":8000}\n",
            "{\"EmpID\":17,\"Name\":\"George\",\"Department\":\"Finance\",\"Salary\":3000}\n",
            "{\"EmpID\":18,\"Name\":\"Nina\",\"Department\":\"IT\",\"Salary\":6000}\n",
            "{\"EmpID\":19,\"Name\":\"Tom\",\"Department\":\"Sales\",\"Salary\":4000}\n",
            "{\"EmpID\":20,\"Name\":\"Anna\",\"Department\":\"HR\",\"Salary\":5000}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv('/content/empdata/employee_data3.csv', header=None)\n",
        "df.columns = ['EmpID', 'Name', 'Department', 'Salary']\n",
        "\n",
        "# Convert to JSON and display\n",
        "json_output = df.to_json(orient='records', lines=True)\n",
        "print(json_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qREZoXBxO9R"
      },
      "outputs": [],
      "source": [
        "query = transformed_df.writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"json\") \\\n",
        "    .option(\"path\", \"/tmp/stream_json_output\") \\\n",
        "    .option(\"checkpointLocation\", \"/tmp/stream_checkpoint\") \\\n",
        "    .start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzgKrwzl541x",
        "outputId": "ffe2f773-6f99-44d3-8542-64cec200cc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+------+---------+------+\n",
            "|Department|EmpID|  Name|NameUPPER|Salary|\n",
            "+----------+-----+------+---------+------+\n",
            "|Department| NULL|  Name|     NAME|  NULL|\n",
            "|        IT|    1|  Anna|     ANNA| 10000|\n",
            "|   Finance|    2|  Nina|     NINA|  8000|\n",
            "| Marketing|    3|  John|     JOHN|  5000|\n",
            "|        IT|    4|George|   GEORGE|  7000|\n",
            "|     Sales|    5|  Nina|     NINA|  8000|\n",
            "|        IT|    6| Emily|    EMILY|  5000|\n",
            "|        HR|    7| David|    DAVID|  8000|\n",
            "| Marketing|    8|George|   GEORGE|  8000|\n",
            "|   Finance|    9|  Jane|     JANE|  5000|\n",
            "| Marketing|   10|  Nina|     NINA|  8000|\n",
            "|        HR|   11|   Tom|      TOM|  9000|\n",
            "| Marketing|   12|  Sara|     SARA|  8000|\n",
            "|   Finance|   13|George|   GEORGE|  8000|\n",
            "|        HR|   14|  Anna|     ANNA|  8000|\n",
            "|        IT|   15|  Jane|     JANE|  4000|\n",
            "|        HR|   16|  Mike|     MIKE|  5000|\n",
            "|        IT|   17|  John|     JOHN|  9000|\n",
            "|   Finance|   18|  John|     JOHN|  9000|\n",
            "|     Sales|   19|  Mike|     MIKE|  6000|\n",
            "+----------+-----+------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.json(\"/tmp/stream_json_output\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "DE-MdYYP6AdG",
        "outputId": "9ad94c61-eb40-4ba8-f8da-65080a9c8b26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌀 Type something (type 'exit' to quit). Every 10 inputs will be saved to a new JSON file.\n",
            ">> pjgpoakpv\n",
            ">> sklngow\\isjg\n",
            ">> kxbmpos\n",
            ">> lkxb;s\n",
            ">> lksmb;l\\\n",
            ">> qkjvwp]salknv\n",
            ">> nsklnbvsl;\n",
            ">> lksanlk\n",
            ">> kjsnvlksm\n",
            ">> jsnvjsn\n",
            "✅ Saved 10 inputs to output_1.json\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-92-3268864005.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "batch = []\n",
        "file_count = 1\n",
        "print(\"🌀 Type something (type 'exit' to quit). Every 10 inputs will be saved to a new JSON file.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\">> \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        if batch:\n",
        "            # Save remaining inputs before exiting\n",
        "            filename = f\"output_{file_count}.json\"\n",
        "            with open(filename, \"w\") as f:\n",
        "                json.dump(batch, f, indent=2)\n",
        "            print(f\"✅ Saved remaining inputs to {filename}\")\n",
        "        print(\"👋 Exiting.\")\n",
        "        break\n",
        "\n",
        "    batch.append({\"input\": user_input})\n",
        "\n",
        "    if len(batch) == 10:\n",
        "        filename = f\"output_{file_count}.json\"\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(batch, f, indent=2)\n",
        "        print(f\"✅ Saved 10 inputs to {filename}\")\n",
        "        batch = []\n",
        "        file_count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyTfIEuQ-xEx",
        "outputId": "bdd9baf7-dd90-4a0a-dad2-89257fa7f3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw_vs_uABWlB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "JvG6zLNd_3EQ",
        "outputId": "58c22eb4-cc42-4a10-b660-7eb573dee374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "🌀 Type something (type 'exit' to quit). Every 10 inputs will be saved to a new JSON file in Google Drive.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-97-2817940857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Create a folder in your Drive to save JSON files\n",
        "output_folder = \"/content/drive/MyDrive/json_inputs/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Step 3: Infinite input loop\n",
        "batch = []\n",
        "file_count = 1\n",
        "print(\"🌀 Type something (type 'exit' to quit). Every 10 inputs will be saved to a new JSON file in Google Drive.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\">> \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        if batch:\n",
        "            filename = os.path.join(output_folder, f\"output_{file_count}.json\")\n",
        "            with open(filename, \"w\") as f:\n",
        "                json.dump(batch, f, indent=2)\n",
        "            print(f\"✅ Saved remaining inputs to {filename}\")\n",
        "        print(\"👋 Exiting.\")\n",
        "        break\n",
        "\n",
        "    batch.append({\"input\": user_input})\n",
        "\n",
        "    if len(batch) == 10:\n",
        "        filename = os.path.join(output_folder, f\"output_{file_count}.json\")\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(batch, f, indent=2)\n",
        "        print(f\"✅ Saved 10 inputs to {filename}\")\n",
        "        batch = []\n",
        "        jkfile_count+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdqe_dhsBSUU",
        "outputId": "9d222864-d0d4-4cb4-c7bc-e7f1f3136866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ File saved: employee_data_20250730_160656.csv\n",
            "✅ File saved: employee_data_20250730_160706.csv\n",
            "✅ File saved: employee_data_20250730_160716.csv\n",
            "✅ File saved: employee_data_20250730_160726.csv\n",
            "✅ File saved: employee_data_20250730_160736.csv\n",
            "✅ File saved: employee_data_20250730_160746.csv\n",
            "✅ File saved: employee_data_20250730_160756.csv\n",
            "✅ File saved: employee_data_20250730_160806.csv\n",
            "✅ File saved: employee_data_20250730_160816.csv\n",
            "✅ File saved: employee_data_20250730_160826.csv\n",
            "✅ File saved: employee_data_20250730_160836.csv\n",
            "✅ File saved: employee_data_20250730_160846.csv\n",
            "✅ File saved: employee_data_20250730_160856.csv\n",
            "✅ File saved: employee_data_20250730_160906.csv\n",
            "✅ File saved: employee_data_20250730_160916.csv\n",
            "✅ File saved: employee_data_20250730_160926.csv\n",
            "✅ File saved: employee_data_20250730_160936.csv\n",
            "✅ File saved: employee_data_20250730_160946.csv\n",
            "✅ File saved: employee_data_20250730_160956.csv\n",
            "✅ File saved: employee_data_20250730_161006.csv\n",
            "✅ File saved: employee_data_20250730_161016.csv\n",
            "✅ File saved: employee_data_20250730_161026.csv\n",
            "✅ File saved: employee_data_20250730_161036.csv\n",
            "✅ File saved: employee_data_20250730_161046.csv\n",
            "✅ File saved: employee_data_20250730_161056.csv\n",
            "✅ File saved: employee_data_20250730_161106.csv\n",
            "✅ File saved: employee_data_20250730_161116.csv\n",
            "✅ File saved: employee_data_20250730_161126.csv\n",
            "✅ File saved: employee_data_20250730_161136.csv\n",
            "✅ File saved: employee_data_20250730_161146.csv\n",
            "✅ File saved: employee_data_20250730_161156.csv\n",
            "✅ File saved: employee_data_20250730_161206.csv\n",
            "✅ File saved: employee_data_20250730_161216.csv\n",
            "✅ File saved: employee_data_20250730_161226.csv\n",
            "✅ File saved: employee_data_20250730_161236.csv\n",
            "✅ File saved: employee_data_20250730_161246.csv\n",
            "✅ File saved: employee_data_20250730_161256.csv\n",
            "✅ File saved: employee_data_20250730_161306.csv\n",
            "✅ File saved: employee_data_20250730_161316.csv\n",
            "✅ File saved: employee_data_20250730_161326.csv\n",
            "✅ File saved: employee_data_20250730_161336.csv\n",
            "✅ File saved: employee_data_20250730_161346.csv\n",
            "✅ File saved: employee_data_20250730_161357.csv\n",
            "✅ File saved: employee_data_20250730_161407.csv\n",
            "✅ File saved: employee_data_20250730_161417.csv\n",
            "✅ File saved: employee_data_20250730_161427.csv\n",
            "✅ File saved: employee_data_20250730_161437.csv\n",
            "✅ File saved: employee_data_20250730_161447.csv\n",
            "✅ File saved: employee_data_20250730_161457.csv\n",
            "✅ File saved: employee_data_20250730_161507.csv\n",
            "✅ File saved: employee_data_20250730_161517.csv\n",
            "✅ File saved: employee_data_20250730_161527.csv\n",
            "✅ File saved: employee_data_20250730_161537.csv\n",
            "✅ File saved: employee_data_20250730_161547.csv\n",
            "✅ File saved: employee_data_20250730_161557.csv\n",
            "✅ File saved: employee_data_20250730_161607.csv\n",
            "✅ File saved: employee_data_20250730_161617.csv\n",
            "✅ File saved: employee_data_20250730_161627.csv\n",
            "✅ File saved: employee_data_20250730_161637.csv\n",
            "✅ File saved: employee_data_20250730_161647.csv\n",
            "✅ File saved: employee_data_20250730_161657.csv\n",
            "✅ File saved: employee_data_20250730_161707.csv\n",
            "✅ File saved: employee_data_20250730_161717.csv\n",
            "✅ File saved: employee_data_20250730_161727.csv\n",
            "✅ File saved: employee_data_20250730_161737.csv\n",
            "✅ File saved: employee_data_20250730_161747.csv\n",
            "✅ File saved: employee_data_20250730_161757.csv\n",
            "✅ File saved: employee_data_20250730_161807.csv\n",
            "✅ File saved: employee_data_20250730_161817.csv\n",
            "✅ File saved: employee_data_20250730_161827.csv\n",
            "✅ File saved: employee_data_20250730_161837.csv\n",
            "✅ File saved: employee_data_20250730_161847.csv\n",
            "✅ File saved: employee_data_20250730_161857.csv\n",
            "✅ File saved: employee_data_20250730_161907.csv\n",
            "✅ File saved: employee_data_20250730_161917.csv\n",
            "✅ File saved: employee_data_20250730_161927.csv\n",
            "✅ File saved: employee_data_20250730_161937.csv\n",
            "✅ File saved: employee_data_20250730_161947.csv\n",
            "✅ File saved: employee_data_20250730_161957.csv\n",
            "✅ File saved: employee_data_20250730_162007.csv\n",
            "✅ File saved: employee_data_20250730_162017.csv\n",
            "✅ File saved: employee_data_20250730_162027.csv\n",
            "✅ File saved: employee_data_20250730_162037.csv\n",
            "✅ File saved: employee_data_20250730_162047.csv\n",
            "✅ File saved: employee_data_20250730_162057.csv\n",
            "✅ File saved: employee_data_20250730_162107.csv\n",
            "✅ File saved: employee_data_20250730_162117.csv\n",
            "✅ File saved: employee_data_20250730_162127.csv\n",
            "✅ File saved: employee_data_20250730_162137.csv\n",
            "✅ File saved: employee_data_20250730_162147.csv\n",
            "✅ File saved: employee_data_20250730_162157.csv\n",
            "✅ File saved: employee_data_20250730_162207.csv\n",
            "✅ File saved: employee_data_20250730_162217.csv\n",
            "✅ File saved: employee_data_20250730_162227.csv\n",
            "✅ File saved: employee_data_20250730_162237.csv\n",
            "✅ File saved: employee_data_20250730_162247.csv\n",
            "✅ File saved: employee_data_20250730_162257.csv\n",
            "✅ File saved: employee_data_20250730_162307.csv\n",
            "✅ File saved: employee_data_20250730_162317.csv\n",
            "✅ File saved: employee_data_20250730_162327.csv\n",
            "✅ File saved: employee_data_20250730_162337.csv\n",
            "✅ File saved: employee_data_20250730_162347.csv\n",
            "✅ File saved: employee_data_20250730_162357.csv\n",
            "✅ File saved: employee_data_20250730_162407.csv\n",
            "✅ File saved: employee_data_20250730_162417.csv\n",
            "✅ File saved: employee_data_20250730_162427.csv\n",
            "✅ File saved: employee_data_20250730_162437.csv\n",
            "✅ File saved: employee_data_20250730_162447.csv\n",
            "✅ File saved: employee_data_20250730_162457.csv\n",
            "✅ File saved: employee_data_20250730_162507.csv\n",
            "✅ File saved: employee_data_20250730_162517.csv\n",
            "✅ File saved: employee_data_20250730_162527.csv\n",
            "✅ File saved: employee_data_20250730_162537.csv\n",
            "✅ File saved: employee_data_20250730_162547.csv\n",
            "✅ File saved: employee_data_20250730_162557.csv\n",
            "✅ File saved: employee_data_20250730_162607.csv\n",
            "✅ File saved: employee_data_20250730_162617.csv\n",
            "✅ File saved: employee_data_20250730_162627.csv\n",
            "✅ File saved: employee_data_20250730_162637.csv\n",
            "✅ File saved: employee_data_20250730_162647.csv\n",
            "✅ File saved: employee_data_20250730_162657.csv\n",
            "✅ File saved: employee_data_20250730_162707.csv\n",
            "✅ File saved: employee_data_20250730_162717.csv\n",
            "✅ File saved: employee_data_20250730_162727.csv\n",
            "✅ File saved: employee_data_20250730_162737.csv\n",
            "✅ File saved: employee_data_20250730_162747.csv\n",
            "✅ File saved: employee_data_20250730_162757.csv\n",
            "✅ File saved: employee_data_20250730_162807.csv\n",
            "✅ File saved: employee_data_20250730_162817.csv\n",
            "✅ File saved: employee_data_20250730_162827.csv\n",
            "✅ File saved: employee_data_20250730_162837.csv\n",
            "✅ File saved: employee_data_20250730_162847.csv\n",
            "✅ File saved: employee_data_20250730_162857.csv\n",
            "✅ File saved: employee_data_20250730_162907.csv\n",
            "✅ File saved: employee_data_20250730_162917.csv\n",
            "✅ File saved: employee_data_20250730_162927.csv\n",
            "✅ File saved: employee_data_20250730_162937.csv\n",
            "✅ File saved: employee_data_20250730_162947.csv\n",
            "✅ File saved: employee_data_20250730_162957.csv\n",
            "✅ File saved: employee_data_20250730_163007.csv\n",
            "✅ File saved: employee_data_20250730_163017.csv\n",
            "✅ File saved: employee_data_20250730_163027.csv\n",
            "✅ File saved: employee_data_20250730_163037.csv\n",
            "✅ File saved: employee_data_20250730_163047.csv\n",
            "✅ File saved: employee_data_20250730_163057.csv\n",
            "✅ File saved: employee_data_20250730_163107.csv\n",
            "✅ File saved: employee_data_20250730_163117.csv\n",
            "✅ File saved: employee_data_20250730_163127.csv\n",
            "✅ File saved: employee_data_20250730_163137.csv\n",
            "✅ File saved: employee_data_20250730_163147.csv\n",
            "✅ File saved: employee_data_20250730_163157.csv\n",
            "✅ File saved: employee_data_20250730_163207.csv\n",
            "✅ File saved: employee_data_20250730_163217.csv\n",
            "✅ File saved: employee_data_20250730_163227.csv\n",
            "✅ File saved: employee_data_20250730_163237.csv\n",
            "✅ File saved: employee_data_20250730_163247.csv\n",
            "✅ File saved: employee_data_20250730_163257.csv\n",
            "✅ File saved: employee_data_20250730_163307.csv\n",
            "✅ File saved: employee_data_20250730_163317.csv\n",
            "✅ File saved: employee_data_20250730_163327.csv\n",
            "✅ File saved: employee_data_20250730_163337.csv\n",
            "✅ File saved: employee_data_20250730_163347.csv\n",
            "✅ File saved: employee_data_20250730_163357.csv\n",
            "✅ File saved: employee_data_20250730_163407.csv\n",
            "✅ File saved: employee_data_20250730_163417.csv\n",
            "✅ File saved: employee_data_20250730_163427.csv\n",
            "✅ File saved: employee_data_20250730_163437.csv\n",
            "✅ File saved: employee_data_20250730_163447.csv\n",
            "✅ File saved: employee_data_20250730_163457.csv\n",
            "✅ File saved: employee_data_20250730_163507.csv\n",
            "✅ File saved: employee_data_20250730_163517.csv\n",
            "✅ File saved: employee_data_20250730_163527.csv\n",
            "✅ File saved: employee_data_20250730_163537.csv\n",
            "✅ File saved: employee_data_20250730_163547.csv\n",
            "✅ File saved: employee_data_20250730_163558.csv\n",
            "✅ File saved: employee_data_20250730_163608.csv\n",
            "✅ File saved: employee_data_20250730_163618.csv\n",
            "✅ File saved: employee_data_20250730_163628.csv\n",
            "✅ File saved: employee_data_20250730_163638.csv\n",
            "✅ File saved: employee_data_20250730_163648.csv\n",
            "✅ File saved: employee_data_20250730_163658.csv\n",
            "✅ File saved: employee_data_20250730_163708.csv\n",
            "✅ File saved: employee_data_20250730_163718.csv\n",
            "✅ File saved: employee_data_20250730_163728.csv\n",
            "✅ File saved: employee_data_20250730_163738.csv\n",
            "✅ File saved: employee_data_20250730_163748.csv\n",
            "✅ File saved: employee_data_20250730_163758.csv\n",
            "✅ File saved: employee_data_20250730_163808.csv\n",
            "✅ File saved: employee_data_20250730_163818.csv\n",
            "✅ File saved: employee_data_20250730_163828.csv\n",
            "✅ File saved: employee_data_20250730_163838.csv\n",
            "✅ File saved: employee_data_20250730_163848.csv\n",
            "✅ File saved: employee_data_20250730_163858.csv\n",
            "✅ File saved: employee_data_20250730_163908.csv\n",
            "✅ File saved: employee_data_20250730_163918.csv\n",
            "✅ File saved: employee_data_20250730_163928.csv\n",
            "✅ File saved: employee_data_20250730_163938.csv\n",
            "✅ File saved: employee_data_20250730_163948.csv\n",
            "✅ File saved: employee_data_20250730_163958.csv\n",
            "✅ File saved: employee_data_20250730_164008.csv\n",
            "✅ File saved: employee_data_20250730_164018.csv\n",
            "✅ File saved: employee_data_20250730_164028.csv\n",
            "✅ File saved: employee_data_20250730_164038.csv\n",
            "✅ File saved: employee_data_20250730_164048.csv\n",
            "✅ File saved: employee_data_20250730_164058.csv\n",
            "✅ File saved: employee_data_20250730_164108.csv\n",
            "✅ File saved: employee_data_20250730_164118.csv\n",
            "✅ File saved: employee_data_20250730_164128.csv\n",
            "✅ File saved: employee_data_20250730_164138.csv\n",
            "✅ File saved: employee_data_20250730_164148.csv\n",
            "✅ File saved: employee_data_20250730_164158.csv\n",
            "✅ File saved: employee_data_20250730_164208.csv\n",
            "✅ File saved: employee_data_20250730_164218.csv\n",
            "✅ File saved: employee_data_20250730_164228.csv\n",
            "✅ File saved: employee_data_20250730_164238.csv\n",
            "✅ File saved: employee_data_20250730_164248.csv\n",
            "✅ File saved: employee_data_20250730_164258.csv\n",
            "✅ File saved: employee_data_20250730_164308.csv\n",
            "✅ File saved: employee_data_20250730_164318.csv\n",
            "✅ File saved: employee_data_20250730_164328.csv\n",
            "✅ File saved: employee_data_20250730_164338.csv\n",
            "✅ File saved: employee_data_20250730_164348.csv\n",
            "✅ File saved: employee_data_20250730_164358.csv\n",
            "✅ File saved: employee_data_20250730_164408.csv\n",
            "✅ File saved: employee_data_20250730_164418.csv\n",
            "✅ File saved: employee_data_20250730_164428.csv\n",
            "✅ File saved: employee_data_20250730_164438.csv\n",
            "✅ File saved: employee_data_20250730_164448.csv\n",
            "✅ File saved: employee_data_20250730_164458.csv\n",
            "✅ File saved: employee_data_20250730_164508.csv\n",
            "✅ File saved: employee_data_20250730_164518.csv\n",
            "✅ File saved: employee_data_20250730_164528.csv\n",
            "✅ File saved: employee_data_20250730_164538.csv\n",
            "✅ File saved: employee_data_20250730_164548.csv\n",
            "✅ File saved: employee_data_20250730_164558.csv\n",
            "✅ File saved: employee_data_20250730_164608.csv\n",
            "✅ File saved: employee_data_20250730_164618.csv\n",
            "✅ File saved: employee_data_20250730_164628.csv\n",
            "✅ File saved: employee_data_20250730_164638.csv\n",
            "✅ File saved: employee_data_20250730_164648.csv\n",
            "✅ File saved: employee_data_20250730_164658.csv\n",
            "✅ File saved: employee_data_20250730_164708.csv\n",
            "✅ File saved: employee_data_20250730_164718.csv\n",
            "✅ File saved: employee_data_20250730_164728.csv\n",
            "✅ File saved: employee_data_20250730_164738.csv\n",
            "✅ File saved: employee_data_20250730_164748.csv\n",
            "✅ File saved: employee_data_20250730_164758.csv\n",
            "✅ File saved: employee_data_20250730_164808.csv\n",
            "✅ File saved: employee_data_20250730_164818.csv\n",
            "✅ File saved: employee_data_20250730_164828.csv\n",
            "✅ File saved: employee_data_20250730_164838.csv\n",
            "✅ File saved: employee_data_20250730_164848.csv\n",
            "✅ File saved: employee_data_20250730_164858.csv\n",
            "✅ File saved: employee_data_20250730_164908.csv\n",
            "✅ File saved: employee_data_20250730_164918.csv\n",
            "✅ File saved: employee_data_20250730_164928.csv\n",
            "✅ File saved: employee_data_20250730_164938.csv\n",
            "✅ File saved: employee_data_20250730_164948.csv\n",
            "✅ File saved: employee_data_20250730_164958.csv\n",
            "✅ File saved: employee_data_20250730_165008.csv\n",
            "✅ File saved: employee_data_20250730_165018.csv\n",
            "✅ File saved: employee_data_20250730_165028.csv\n",
            "✅ File saved: employee_data_20250730_165038.csv\n",
            "✅ File saved: employee_data_20250730_165048.csv\n",
            "✅ File saved: employee_data_20250730_165058.csv\n",
            "✅ File saved: employee_data_20250730_165108.csv\n",
            "✅ File saved: employee_data_20250730_165118.csv\n",
            "✅ File saved: employee_data_20250730_165128.csv\n",
            "✅ File saved: employee_data_20250730_165138.csv\n",
            "✅ File saved: employee_data_20250730_165148.csv\n",
            "✅ File saved: employee_data_20250730_165158.csv\n",
            "✅ File saved: employee_data_20250730_165208.csv\n",
            "✅ File saved: employee_data_20250730_165218.csv\n",
            "✅ File saved: employee_data_20250730_165228.csv\n",
            "✅ File saved: employee_data_20250730_165238.csv\n",
            "✅ File saved: employee_data_20250730_165248.csv\n",
            "✅ File saved: employee_data_20250730_165258.csv\n",
            "✅ File saved: employee_data_20250730_165308.csv\n",
            "✅ File saved: employee_data_20250730_165318.csv\n",
            "✅ File saved: employee_data_20250730_165328.csv\n",
            "✅ File saved: employee_data_20250730_165338.csv\n",
            "✅ File saved: employee_data_20250730_165348.csv\n",
            "✅ File saved: employee_data_20250730_165358.csv\n",
            "✅ File saved: employee_data_20250730_165408.csv\n",
            "✅ File saved: employee_data_20250730_165418.csv\n",
            "✅ File saved: employee_data_20250730_165428.csv\n",
            "✅ File saved: employee_data_20250730_165438.csv\n",
            "✅ File saved: employee_data_20250730_165448.csv\n",
            "✅ File saved: employee_data_20250730_165458.csv\n",
            "✅ File saved: employee_data_20250730_165508.csv\n",
            "✅ File saved: employee_data_20250730_165518.csv\n",
            "✅ File saved: employee_data_20250730_165528.csv\n",
            "✅ File saved: employee_data_20250730_165538.csv\n",
            "✅ File saved: employee_data_20250730_165548.csv\n",
            "✅ File saved: employee_data_20250730_165558.csv\n",
            "✅ File saved: employee_data_20250730_165608.csv\n",
            "✅ File saved: employee_data_20250730_165618.csv\n",
            "✅ File saved: employee_data_20250730_165628.csv\n",
            "✅ File saved: employee_data_20250730_165638.csv\n",
            "✅ File saved: employee_data_20250730_165648.csv\n",
            "✅ File saved: employee_data_20250730_165658.csv\n",
            "✅ File saved: employee_data_20250730_165709.csv\n",
            "✅ File saved: employee_data_20250730_165719.csv\n",
            "✅ File saved: employee_data_20250730_165729.csv\n",
            "✅ File saved: employee_data_20250730_165739.csv\n",
            "✅ File saved: employee_data_20250730_165749.csv\n",
            "✅ File saved: employee_data_20250730_165759.csv\n",
            "✅ File saved: employee_data_20250730_165809.csv\n",
            "✅ File saved: employee_data_20250730_165819.csv\n",
            "✅ File saved: employee_data_20250730_165829.csv\n",
            "✅ File saved: employee_data_20250730_165839.csv\n",
            "✅ File saved: employee_data_20250730_165849.csv\n",
            "✅ File saved: employee_data_20250730_165859.csv\n",
            "✅ File saved: employee_data_20250730_165909.csv\n",
            "✅ File saved: employee_data_20250730_165919.csv\n",
            "✅ File saved: employee_data_20250730_165929.csv\n",
            "✅ File saved: employee_data_20250730_165939.csv\n",
            "✅ File saved: employee_data_20250730_165949.csv\n",
            "✅ File saved: employee_data_20250730_165959.csv\n",
            "✅ File saved: employee_data_20250730_170009.csv\n",
            "✅ File saved: employee_data_20250730_170019.csv\n",
            "✅ File saved: employee_data_20250730_170029.csv\n",
            "✅ File saved: employee_data_20250730_170039.csv\n",
            "✅ File saved: employee_data_20250730_170049.csv\n",
            "✅ File saved: employee_data_20250730_170059.csv\n",
            "✅ File saved: employee_data_20250730_170109.csv\n",
            "✅ File saved: employee_data_20250730_170119.csv\n",
            "✅ File saved: employee_data_20250730_170129.csv\n",
            "✅ File saved: employee_data_20250730_170139.csv\n",
            "✅ File saved: employee_data_20250730_170149.csv\n",
            "✅ File saved: employee_data_20250730_170159.csv\n",
            "✅ File saved: employee_data_20250730_170209.csv\n",
            "✅ File saved: employee_data_20250730_170219.csv\n",
            "✅ File saved: employee_data_20250730_170229.csv\n",
            "✅ File saved: employee_data_20250730_170239.csv\n",
            "✅ File saved: employee_data_20250730_170249.csv\n",
            "✅ File saved: employee_data_20250730_170259.csv\n",
            "✅ File saved: employee_data_20250730_170309.csv\n",
            "✅ File saved: employee_data_20250730_170319.csv\n",
            "✅ File saved: employee_data_20250730_170329.csv\n",
            "✅ File saved: employee_data_20250730_170339.csv\n",
            "✅ File saved: employee_data_20250730_170349.csv\n",
            "✅ File saved: employee_data_20250730_170359.csv\n",
            "✅ File saved: employee_data_20250730_170409.csv\n",
            "✅ File saved: employee_data_20250730_170419.csv\n",
            "✅ File saved: employee_data_20250730_170429.csv\n",
            "✅ File saved: employee_data_20250730_170439.csv\n",
            "✅ File saved: employee_data_20250730_170449.csv\n",
            "✅ File saved: employee_data_20250730_170459.csv\n",
            "✅ File saved: employee_data_20250730_170509.csv\n",
            "✅ File saved: employee_data_20250730_170519.csv\n",
            "✅ File saved: employee_data_20250730_170529.csv\n",
            "✅ File saved: employee_data_20250730_170539.csv\n",
            "✅ File saved: employee_data_20250730_170549.csv\n",
            "✅ File saved: employee_data_20250730_170559.csv\n",
            "✅ File saved: employee_data_20250730_170609.csv\n",
            "✅ File saved: employee_data_20250730_170619.csv\n",
            "✅ File saved: employee_data_20250730_170629.csv\n",
            "✅ File saved: employee_data_20250730_170639.csv\n",
            "✅ File saved: employee_data_20250730_170649.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from faker import Faker\n",
        "import random\n",
        "import uuid\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Output directory in Google Drive\n",
        "output_dir = \"/content/drive/MyDrive/employee_batches\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Infinite loop to keep generating files\n",
        "while True:\n",
        "    # Generate unique filename using current time\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    file_name = f\"employee_data_{timestamp}.csv\"\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "    # Write 10 employee records to this file\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(\"EmpID,Name,Department,Salary,UniqueID\\n\")  # Header\n",
        "        for _ in range(10):\n",
        "            emp_id = random.randint(1000, 9999)\n",
        "            name = fake.name()\n",
        "            department = fake.job()\n",
        "            salary = random.randint(3000, 12000)\n",
        "\n",
        "\n",
        "            record = f\"{emp_id},{name},{department},{salary}\\n\"\n",
        "            f.write(record)\n",
        "\n",
        "    print(f\"✅ File saved: {file_name}\")\n",
        "\n",
        "    time.sleep(10)  # Wait 30 seconds before generating the next file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpjslX8PFO7e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Set the folder path where your CSVs are stored\n",
        "csv_folder = \"/content/drive/MyDrive/employee_batches\"\n",
        "\n",
        "# Folder to save JSON files (optional)\n",
        "json_folder = \"/content/drive/MyDrive/employee_jsons\"\n",
        "os.makedirs(json_folder, exist_ok=True)\n",
        "\n",
        "csv_files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
        "\n",
        "def read():\n",
        "  for csv_file in csv_files:\n",
        "      csv_path = os.path.join(csv_folder, csv_file)\n",
        "\n",
        "      # Read CSV into DataFrame\n",
        "      df = pd.read_csv(csv_path)\n",
        "\n",
        "      # Convert DataFrame to list of dicts (JSON)\n",
        "      json_data = df.to_dict(orient=\"records\")\n",
        "\n",
        "      # Save JSON to file\n",
        "      json_filename = csv_file.replace(\".csv\", \".json\")\n",
        "      json_path = os.path.join(json_folder, json_filename)\n",
        "\n",
        "      with open(json_path, \"w\") as json_file:\n",
        "          json.dump(json_data, json_file, indent=4)\n",
        "\n",
        "      # Print output\n",
        "      print(f\"\\n✅ Converted: {csv_file} → {json_filename}\")\n",
        "      print(\"📄 JSON Data Preview:\")\n",
        "      print(json.dumps(json_data, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f728492",
        "outputId": "ee41a1e0-9d8f-46ee-c524-fff8586d66b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.5.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install faker"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark / Scala Programming Basics Day 6"
      ],
      "metadata": {
        "id": "RKwRdbgBzups"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "h4Hv0SDoul_p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq >/dev/null"
      ],
      "metadata": {
        "id": "nmGM5Gn2unBM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dGPqz3Hv6be",
        "outputId": "6be7e37f-4230-4fbb-c627-98bf53f77161"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.28\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.28+6-post-Ubuntu-1ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/scala/scala/releases/download/v2.12.18/scala-2.12.18.deb"
      ],
      "metadata": {
        "id": "5mxWfDKUwC2u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -i scala-2.12.18.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g5VNbZ0wJoq",
        "outputId": "7a5e2772-59bc-4479-f867-f45d76ebc3c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package scala.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 126633 files and directories currently installed.)\n",
            "Preparing to unpack scala-2.12.18.deb ...\n",
            "Unpacking scala (2.12.18-400) ...\n",
            "Setting up scala (2.12.18-400) ...\n",
            "Creating system group: scala\n",
            "Creating system user: scala in scala with scala daemon-user and shell /bin/false\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.4.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "-FeCoMKcwQep"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /usr/lib/jvm/java-1.11.0-openjdk-amd64/\n",
        "!ls /content/spark-3.4.1-bin-hadoop3/\n",
        "!ls /content/scala-2.12.18.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao8_3VVIwbSD",
        "outputId": "17b5fc82-d959-45a0-bf54-97cf49712a9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin  conf  docs  include  jmods  legal\tlib  man  release\n",
            "bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n",
            "conf  examples\tkubernetes  licenses  python  README.md  sbin\n",
            "/content/scala-2.12.18.deb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"]=\"/content/spark-3.4.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "giP6kK36w61a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $JAVA_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f-gXQxE0Pe6",
        "outputId": "ab0fadbe-4509-482b-a84a-e451dde6b638"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-11-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $SPARK_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq9MWmMC0S_7",
        "outputId": "78a8874b-c8c9-46b6-e74f-fd692753e7f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spark-3.4.1-bin-hadoop3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "gMpCAjyz0WHN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder\\\n",
        "  .appName(\"Colab Scala Spark\") \\\n",
        "  .getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Im0Tv-5u07Wr",
        "outputId": "5edc7361-2c5c-49a0-dd7d-93d9a9e847a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ad7edda9190>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://753c7acefc6b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab Scala Spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile HelloWorld.scala\n",
        "object HelloWorld{\n",
        "    def main(args: Array[String]): Unit={\n",
        "        println(\"Welcome from Scala\")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zClC-qZA1xSL",
        "outputId": "a12e2265-2078-4df3-8e5d-d961a163a32a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting HelloWorld.scala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08oPZIiw3lDw",
        "outputId": "4213c677-1d9e-40e3-b54b-0a7e92b4ca79"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HelloWorld.scala  scala-2.12.18.deb\t   spark-3.4.1-bin-hadoop3.tgz\n",
            "sample_data\t  spark-3.4.1-bin-hadoop3  spark-3.4.1-bin-hadoop3.tgz.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scalac HelloWorld.scala"
      ],
      "metadata": {
        "id": "QJX2I9gv3n2L"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRoZ10uH3zmN",
        "outputId": "39065097-28c8-45ce-9ffa-b06023e3cf79"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'HelloWorld$.class'   sample_data\t        spark-3.4.1-bin-hadoop3.tgz\n",
            " HelloWorld.class     scala-2.12.18.deb         spark-3.4.1-bin-hadoop3.tgz.1\n",
            " HelloWorld.scala     spark-3.4.1-bin-hadoop3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scala HelloWorld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh1TEtUU4D1Q",
        "outputId": "3badaa89-bc86-4d92-efa0-1c0711bc4fb8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome from Scala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CompleteScalaDemo.scala\n",
        "object CompleteScalaDemo{\n",
        "  def main(args: Array[String]) : Unit={\n",
        "  // Step1: Basic Syntax and variables\n",
        "  val language: String = \"Scala\"\n",
        "  var version: Double = 2.12\n",
        "  println(s\"Step 1 : Welcome to $language version $version\")\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKtYzfxG4MSu",
        "outputId": "db316ad4-7555-42f6-bc15-6366e84b61ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CompleteScalaDemo.scala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scalac CompleteScalaDemo.scala"
      ],
      "metadata": {
        "id": "aP848FQL55Gu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scala CompleteScalaDemo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7rqyCF157jU",
        "outputId": "6efdab2d-fe81-41be-eee8-5b6ad6f2490f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 : Welcome to Scala version 2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile LoopDemo.scala\n",
        "object LoopDemo {\n",
        "  def main(args: Array[String]): Unit = {\n",
        "    println(\"Demo: While Loop\")\n",
        "    var i = 1\n",
        "    while (i <= 5) {\n",
        "      println(s\"While Loop iteration: $i\")\n",
        "      i += 1\n",
        "    }\n",
        "\n",
        "    println(\"\\nDemo: Do-While Loop\")\n",
        "    var j = 1\n",
        "    do {\n",
        "      println(s\"Do-While Loop iteration: $j\")\n",
        "      j += 1\n",
        "    } while (j <= 5)\n",
        "\n",
        "    println(\"\\nDemo: For Loop with Range\")\n",
        "    for (k <- 1 to 5) {\n",
        "      println(s\"For Loop iteration: $k\")\n",
        "    }\n",
        "\n",
        "    println(\"\\nDemo: For Loop with Guards (only even numbers)\")\n",
        "    for (k <- 1 to 10 if k % 2 == 0) {\n",
        "      println(s\"Even number: $k\")\n",
        "    }\n",
        "\n",
        "    println(\"\\nDemo: For Loop with yield (creates a collection)\")\n",
        "    val squares = for (k <- 1 to 5) yield k * k\n",
        "    println(s\"Squares from 1 to 5: ${squares.mkString(\",\")}\")\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4wyPiTu6Gtp",
        "outputId": "b96ae349-2124-4439-d9b6-70acc1bde054"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing LoopDemo.scala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scalac LoopDemo.scala\n",
        "!scala LoopDemo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua8yDyjKK-dA",
        "outputId": "e14197b4-9f63-4e69-8042-1b4970144771"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo: While Loop\n",
            "While Loop iteration: 1\n",
            "While Loop iteration: 2\n",
            "While Loop iteration: 3\n",
            "While Loop iteration: 4\n",
            "While Loop iteration: 5\n",
            "\n",
            "Demo: Do-While Loop\n",
            "Do-While Loop iteration: 1\n",
            "Do-While Loop iteration: 2\n",
            "Do-While Loop iteration: 3\n",
            "Do-While Loop iteration: 4\n",
            "Do-While Loop iteration: 5\n",
            "\n",
            "Demo: For Loop with Range\n",
            "For Loop iteration: 1\n",
            "For Loop iteration: 2\n",
            "For Loop iteration: 3\n",
            "For Loop iteration: 4\n",
            "For Loop iteration: 5\n",
            "\n",
            "Demo: For Loop with Guards (only even numbers)\n",
            "Even number: 2\n",
            "Even number: 4\n",
            "Even number: 6\n",
            "Even number: 8\n",
            "Even number: 10\n",
            "\n",
            "Demo: For Loop with yield (creates a collection)\n",
            "Squares from 1 to 5: 1,4,9,16,25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOi9lJ-SLS_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "GUO7okyBshqq",
        "ijZbN5F4ttVO",
        "EpPnpP-oxBDw",
        "RCvuGCzBN8EW",
        "mCPIk367Ydfh",
        "2mPR-sWAi4zz"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyP7GnFThV2Xx2GapX/gq1Se",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}